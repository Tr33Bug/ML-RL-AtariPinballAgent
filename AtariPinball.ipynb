{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0CXP1j7ZE-y"
   },
   "source": [
    "# Video Pinball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfohG30UZE-1"
   },
   "source": [
    "This project aims to teach a reinforcement learning agent to play the game [Atari Video Pinball](https://gymnasium.farama.org/environments/atari/video_pinball/).  \n",
    "For this purpose, the Deep Q-Learning approach is followed using a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oha95PZYZE-2"
   },
   "source": [
    "## Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uto_yJs4ZE-3"
   },
   "source": [
    "General information:\n",
    "\n",
    "|                   |                                   |\n",
    "| ----------------- | --------------------------------- |\n",
    "| Action Space      | Discrete(18)                      |\n",
    "| Observation Space | (210, 160, 3)                     |\n",
    "| Observation High  | 255                               |\n",
    "| Observation Low   | 0                                 |\n",
    "| Import            | `gym.make(\"ALE/VideoPinball-v5\")` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsq5OxhTZE-3"
   },
   "source": [
    "### Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZmT7C3NZE-3"
   },
   "source": [
    "The `Video Pinball` Game form the Atari (2600) environment has the following actions which are described in the [manual of the game](https://atariage.com/manual_html_page.php?SoftwareLabelID=588):\n",
    "**This is the reduced action space, which is available when choosing `v0`, `v4` or specifying `full_action_space=false` during initialization. Otherwise more actions will be available.**\n",
    "\n",
    "| Num | Action    | Description                                                                                  |\n",
    "| --- | --------- | -------------------------------------------------------------------------------------------- |\n",
    "| 0   | NOOP      | No Operation                                                                                 |\n",
    "| 1   | FIRE      | Press the red controller button to release the spring and shoot the ball into the playfield. |\n",
    "| 2   | UP        | Move the Joystick up to move both flippers at the same time.                                 |\n",
    "| 3   | RIGHT     | Move the Joystick to the right to move the right flipper up.                                 |\n",
    "| 4   | LEFT      | Move the Joystick to the left to move the left flipper up.                                   |\n",
    "| 5   | DOWN      | Pull the Joystick down (towards you) to bring the plunger back.                              |\n",
    "| 6   | UPFIRE    | \"Nudge\" the ball into upwards direction.                                                     |\n",
    "| 7   | RIGHTFIRE | \"Nudge\" the ball to the right.                                                               |\n",
    "| 8   | LEFTFIRE  | \"Nudge\" the ball to the left.                                                                |\n",
    "\n",
    "Furthermore it might be interesting to try different modes/difficulties of the game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aXY11AEZE-4"
   },
   "source": [
    "### Difficulties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmu_V-S3ZE-5"
   },
   "source": [
    "There are two available difficulties:\n",
    "\n",
    "- `a` (aka. pinbal wizards) is for expert players and has two additional drain holes at the bottom\n",
    "- `b` is for the beginning/novice players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXbi9DXyZE-5"
   },
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uopuLRE6ZE-5"
   },
   "source": [
    "By default, the environment returns the RGB image which is displayed to human players as an observation.  \n",
    "However it is possible to observe\n",
    "- The 128 Bytes of RAM of the console (`Box([0 ... 0], [255 ... 255], (128,), uint8)`)\n",
    "- A grayscale image (`Box([[0 ... 0] ... [0  ... 0]], [[255 ... 255] ... [255  ... 255]], (250, 160), uint8)`)\n",
    "\n",
    "instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXoodpnfZE-6"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0SEDNjFZE-6"
   },
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-06T19:48:33.726357Z",
     "iopub.status.busy": "2023-01-06T19:48:33.725352Z",
     "iopub.status.idle": "2023-01-06T19:48:48.867345Z",
     "shell.execute_reply": "2023-01-06T19:48:48.866311Z",
     "shell.execute_reply.started": "2023-01-06T19:48:33.726277Z"
    },
    "id": "l5_4qIlyfODG",
    "outputId": "60bf481f-297c-4605-fb2b-5ad56edf87af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:2 https://deb.nodesource.com/node_16.x focal InRelease [4583 B]            \n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]        \n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]      \n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]      \n",
      "Get:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB] \n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]   \n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2859 kB]\n",
      "Get:12 https://deb.nodesource.com/node_16.x focal/main amd64 Packages [773 B]  \n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1929 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.3 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1277 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
      "Get:18 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1812 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [976 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2391 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.7 kB]\n",
      "Fetched 24.9 MB in 2s (11.1 MB/s)                            \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  freeglut3 libfontenc1 libglu1-mesa libpython2-stdlib libpython2.7-minimal\n",
      "  libpython2.7-stdlib libunwind8 libxfont2 libxkbfile1 libxmuu1 python2\n",
      "  python2-minimal python2.7 python2.7-minimal x11-xkb-utils xauth xfonts-base\n",
      "  xfonts-encodings xfonts-utils xserver-common\n",
      "Suggested packages:\n",
      "  python-tk python-numpy libgle3 python2-doc python2.7-doc binfmt-support\n",
      "The following NEW packages will be installed:\n",
      "  freeglut3 libfontenc1 libglu1-mesa libpython2-stdlib libpython2.7-minimal\n",
      "  libpython2.7-stdlib libunwind8 libxfont2 libxkbfile1 libxmuu1 python-opengl\n",
      "  python2 python2-minimal python2.7 python2.7-minimal x11-xkb-utils xauth\n",
      "  xfonts-base xfonts-encodings xfonts-utils xserver-common xvfb\n",
      "0 upgraded, 22 newly installed, 0 to remove and 113 not upgraded.\n",
      "Need to get 12.3 MB of archives.\n",
      "After this operation, 34.9 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-minimal amd64 2.7.18-1~20.04.3 [336 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7-minimal amd64 2.7.18-1~20.04.3 [1280 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpython2.7-stdlib amd64 2.7.18-1~20.04.3 [1888 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python2.7 amd64 2.7.18-1~20.04.3 [248 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7072 B]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 libxmuu1 amd64 2:1.1.3-0ubuntu1 [9728 B]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 xauth amd64 1:1.1-0ubuntu1 [25.0 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 libunwind8 amd64 1.2.1-9build1 [47.6 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfont2 amd64 1:2.0.3-1 [91.7 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 libglu1-mesa amd64 9.0.1-1build1 [168 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-xkb-utils amd64 7.7+5 [158 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu1 [573 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-base all 1:1.0.5 [5896 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-common all 2:1.20.13-1ubuntu1~20.04.5 [27.1 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.5 [780 kB]\n",
      "Fetched 12.3 MB in 0s (44.1 MB/s)\n",
      "Selecting previously unselected package libpython2.7-minimal:amd64.\n",
      "(Reading database ... 78556 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libpython2.7-minimal_2.7.18-1~20.04.3_amd64.deb ...\n",
      "Unpacking libpython2.7-minimal:amd64 (2.7.18-1~20.04.3) ...\n",
      "Selecting previously unselected package python2.7-minimal.\n",
      "Preparing to unpack .../1-python2.7-minimal_2.7.18-1~20.04.3_amd64.deb ...\n",
      "Unpacking python2.7-minimal (2.7.18-1~20.04.3) ...\n",
      "Selecting previously unselected package python2-minimal.\n",
      "Preparing to unpack .../2-python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n",
      "Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n",
      "Selecting previously unselected package libpython2.7-stdlib:amd64.\n",
      "Preparing to unpack .../3-libpython2.7-stdlib_2.7.18-1~20.04.3_amd64.deb ...\n",
      "Unpacking libpython2.7-stdlib:amd64 (2.7.18-1~20.04.3) ...\n",
      "Selecting previously unselected package python2.7.\n",
      "Preparing to unpack .../4-python2.7_2.7.18-1~20.04.3_amd64.deb ...\n",
      "Unpacking python2.7 (2.7.18-1~20.04.3) ...\n",
      "Selecting previously unselected package libpython2-stdlib:amd64.\n",
      "Preparing to unpack .../5-libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n",
      "Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
      "Setting up libpython2.7-minimal:amd64 (2.7.18-1~20.04.3) ...\n",
      "Setting up python2.7-minimal (2.7.18-1~20.04.3) ...\n",
      "Linking and byte-compiling packages for runtime python2.7...\n",
      "Setting up python2-minimal (2.7.17-2ubuntu4) ...\n",
      "Selecting previously unselected package python2.\n",
      "(Reading database ... 79303 files and directories currently installed.)\n",
      "Preparing to unpack .../00-python2_2.7.17-2ubuntu4_amd64.deb ...\n",
      "Unpacking python2 (2.7.17-2ubuntu4) ...\n",
      "Selecting previously unselected package libxmuu1:amd64.\n",
      "Preparing to unpack .../01-libxmuu1_2%3a1.1.3-0ubuntu1_amd64.deb ...\n",
      "Unpacking libxmuu1:amd64 (2:1.1.3-0ubuntu1) ...\n",
      "Selecting previously unselected package xauth.\n",
      "Preparing to unpack .../02-xauth_1%3a1.1-0ubuntu1_amd64.deb ...\n",
      "Unpacking xauth (1:1.1-0ubuntu1) ...\n",
      "Selecting previously unselected package freeglut3:amd64.\n",
      "Preparing to unpack .../03-freeglut3_2.8.1-3_amd64.deb ...\n",
      "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
      "Selecting previously unselected package libfontenc1:amd64.\n",
      "Preparing to unpack .../04-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
      "Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
      "Selecting previously unselected package libunwind8:amd64.\n",
      "Preparing to unpack .../05-libunwind8_1.2.1-9build1_amd64.deb ...\n",
      "Unpacking libunwind8:amd64 (1.2.1-9build1) ...\n",
      "Selecting previously unselected package libxfont2:amd64.\n",
      "Preparing to unpack .../06-libxfont2_1%3a2.0.3-1_amd64.deb ...\n",
      "Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n",
      "Selecting previously unselected package libxkbfile1:amd64.\n",
      "Preparing to unpack .../07-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
      "Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
      "Selecting previously unselected package libglu1-mesa:amd64.\n",
      "Preparing to unpack .../08-libglu1-mesa_9.0.1-1build1_amd64.deb ...\n",
      "Unpacking libglu1-mesa:amd64 (9.0.1-1build1) ...\n",
      "Selecting previously unselected package python-opengl.\n",
      "Preparing to unpack .../09-python-opengl_3.1.0+dfsg-2build1_all.deb ...\n",
      "Unpacking python-opengl (3.1.0+dfsg-2build1) ...\n",
      "Selecting previously unselected package x11-xkb-utils.\n",
      "Preparing to unpack .../10-x11-xkb-utils_7.7+5_amd64.deb ...\n",
      "Unpacking x11-xkb-utils (7.7+5) ...\n",
      "Selecting previously unselected package xfonts-encodings.\n",
      "Preparing to unpack .../11-xfonts-encodings_1%3a1.0.5-0ubuntu1_all.deb ...\n",
      "Unpacking xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
      "Selecting previously unselected package xfonts-utils.\n",
      "Preparing to unpack .../12-xfonts-utils_1%3a7.7+6_amd64.deb ...\n",
      "Unpacking xfonts-utils (1:7.7+6) ...\n",
      "Selecting previously unselected package xfonts-base.\n",
      "Preparing to unpack .../13-xfonts-base_1%3a1.0.5_all.deb ...\n",
      "Unpacking xfonts-base (1:1.0.5) ...\n",
      "Selecting previously unselected package xserver-common.\n",
      "Preparing to unpack .../14-xserver-common_2%3a1.20.13-1ubuntu1~20.04.5_all.deb ...\n",
      "Unpacking xserver-common (2:1.20.13-1ubuntu1~20.04.5) ...\n",
      "Selecting previously unselected package xvfb.\n",
      "Preparing to unpack .../15-xvfb_2%3a1.20.13-1ubuntu1~20.04.5_amd64.deb ...\n",
      "Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.5) ...\n",
      "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
      "Setting up libunwind8:amd64 (1.2.1-9build1) ...\n",
      "Setting up libpython2.7-stdlib:amd64 (2.7.18-1~20.04.3) ...\n",
      "Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
      "Setting up xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
      "Setting up libglu1-mesa:amd64 (9.0.1-1build1) ...\n",
      "Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
      "Setting up libxfont2:amd64 (1:2.0.3-1) ...\n",
      "Setting up libxmuu1:amd64 (2:1.1.3-0ubuntu1) ...\n",
      "Setting up python2.7 (2.7.18-1~20.04.3) ...\n",
      "Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
      "Setting up x11-xkb-utils (7.7+5) ...\n",
      "Setting up xfonts-utils (1:7.7+6) ...\n",
      "Setting up python2 (2.7.17-2ubuntu4) ...\n",
      "Setting up xfonts-base (1:1.0.5) ...\n",
      "Setting up xauth (1:1.1-0ubuntu1) ...\n",
      "Setting up xserver-common (2:1.20.13-1ubuntu1~20.04.5) ...\n",
      "Setting up python-opengl (3.1.0+dfsg-2build1) ...\n",
      "Setting up xvfb (2:1.20.13-1ubuntu1~20.04.5) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
      "Processing triggers for mime-support (3.64ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.7) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y xvfb python-opengl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-06T19:48:48.870415Z",
     "iopub.status.busy": "2023-01-06T19:48:48.869974Z",
     "iopub.status.idle": "2023-01-06T19:49:47.086129Z",
     "shell.execute_reply": "2023-01-06T19:49:47.084655Z",
     "shell.execute_reply.started": "2023-01-06T19:48:48.870374Z"
    },
    "id": "DWU1zl7jZE-7",
    "outputId": "c0db7be7-9e0f-4fe6-c300-c4017a69be24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade pip\n",
    "%pip install -q gym==0.21.0\n",
    "%pip install -q 'gym[atari]==0.12.5'\n",
    "%pip install -q matplotlib\n",
    "%pip install -q pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f7F9DYhOUy-"
   },
   "source": [
    "### Download required files from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-06T19:49:47.091167Z",
     "iopub.status.busy": "2023-01-06T19:49:47.090816Z",
     "iopub.status.idle": "2023-01-06T19:49:47.099633Z",
     "shell.execute_reply": "2023-01-06T19:49:47.098162Z",
     "shell.execute_reply.started": "2023-01-06T19:49:47.091124Z"
    },
    "id": "X31W6SxqO2Rg",
    "outputId": "4eef9cbd-0e16-45e3-fda6-4d5078012242"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    %pip install -q --upgrade gdown\n",
    "    from gdown import download_folder\n",
    "\n",
    "    download_folder(\"https://drive.google.com/drive/folders/1SW56nbccfHJtC6oGBIcp7XCeJDkKehGK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhpjsB9bZE-8"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-06T19:49:47.101516Z",
     "iopub.status.busy": "2023-01-06T19:49:47.101165Z",
     "iopub.status.idle": "2023-01-06T19:49:54.951778Z",
     "shell.execute_reply": "2023-01-06T19:49:54.950615Z",
     "shell.execute_reply.started": "2023-01-06T19:49:47.101488Z"
    },
    "id": "iTdn0YfeZE-8",
    "outputId": "b80af935-b178-4b57-9b3a-605e41c16a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import deque\n",
    "from contextlib import suppress\n",
    "from datetime import datetime\n",
    "from random import sample\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras.layers import Conv2D, Dense, Flatten, Input, Lambda, multiply\n",
    "from keras.losses import huber_loss\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from pyvirtualdisplay import Display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# local files\n",
    "from external.abstract_agent import AbstractAgent\n",
    "from external.atari_helpers import LazyFrames, make_atari, wrap_deepmind\n",
    "from external.loggers import TensorBoardLogger, tf_summary_image\n",
    "from external.plot_utils import plot_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T19:49:54.955659Z",
     "iopub.status.busy": "2023-01-06T19:49:54.954886Z",
     "iopub.status.idle": "2023-01-06T19:49:55.462314Z",
     "shell.execute_reply": "2023-01-06T19:49:55.460986Z",
     "shell.execute_reply.started": "2023-01-06T19:49:54.955617Z"
    },
    "id": "OXBi9qXufV-l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f5cb3e5a6a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "    from IPython.display import SVG\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgU4OVMIZE-9"
   },
   "source": [
    "### Extended DQN-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T19:49:55.464495Z",
     "iopub.status.busy": "2023-01-06T19:49:55.464187Z",
     "iopub.status.idle": "2023-01-06T19:49:55.485976Z",
     "shell.execute_reply": "2023-01-06T19:49:55.484196Z",
     "shell.execute_reply.started": "2023-01-06T19:49:55.464464Z"
    },
    "id": "iaJZTcGhZE-9"
   },
   "outputs": [],
   "source": [
    "class AbstractDQNAgent(AbstractAgent):\n",
    "    __slots__ = [\n",
    "        \"action_size\",\n",
    "        \"state_size\",\n",
    "        \"gamma\",\n",
    "        \"epsilon\",\n",
    "        \"epsilon_decay\",\n",
    "        \"epsilon_min\",\n",
    "        \"alpha\",\n",
    "        \"batch_size\",\n",
    "        \"memory_size\",\n",
    "        \"start_replay_step\",\n",
    "        \"target_model_update_interval\",\n",
    "        \"train_freq\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self,\n",
    "                 action_size: int,\n",
    "                 state_size: int,\n",
    "                 gamma: float,\n",
    "                 epsilon: float,\n",
    "                 epsilon_decay: float,\n",
    "                 epsilon_min: float,\n",
    "                 alpha: float,\n",
    "                 batch_size: int,\n",
    "                 memory_size: int,\n",
    "                 start_replay_step: int,\n",
    "                 target_model_update_interval: int,\n",
    "                 train_freq: int,\n",
    "                 ):\n",
    "        self.action_size = action_size\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.replay_has_started = False\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.memory_size = memory_size\n",
    "        self.memory = deque(maxlen=self.memory_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.step = 0\n",
    "        self.start_replay_step = start_replay_step\n",
    "\n",
    "        self.target_model_update_interval = target_model_update_interval\n",
    "\n",
    "        self.train_freq = train_freq\n",
    "\n",
    "        assert self.start_replay_step >= self.batch_size, \"The number of steps to start replay must be at least as large as the batch size\"\n",
    "\n",
    "        self.action_mask = np.ones((1, self.action_size))\n",
    "        self.action_mask_batch = np.ones((self.batch_size, self.action_size))\n",
    "\n",
    "        self.tf_config_intra_threads = 8\n",
    "        self.tf_config_inter_threads = 4\n",
    "        self.tf_config_soft_placement = True\n",
    "        self.tf_config_allow_growth = True\n",
    "\n",
    "        config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=self.tf_config_intra_threads,\n",
    "                                inter_op_parallelism_threads=self.tf_config_inter_threads,\n",
    "                                allow_soft_placement=self.tf_config_soft_placement\n",
    "                                )\n",
    "\n",
    "        config.gpu_options.allow_growth = self.tf_config_allow_growth\n",
    "        session = tf.compat.v1.Session(config=config)\n",
    "        set_session(session)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "\n",
    "    def save(self, target_path: str) -> None:\n",
    "      \"\"\"\n",
    "        Saves the current state of the DQNAgent to some output files.\n",
    "        Together with `load` this serves as a very rudimentary checkpointing.\n",
    "      \"\"\"\n",
    "      agent_dict = {\n",
    "            \"agent_init\": {},\n",
    "            \"agent_params\": {},\n",
    "            \"tf_config\": {}\n",
    "        }\n",
    "\n",
    "      if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "\n",
    "      for slot in self.__slots__:\n",
    "          agent_dict[\"agent_init\"].update({slot: getattr(self, slot)})\n",
    "\n",
    "      agent_dict[\"agent_init\"].update({\"memory_size\": self.memory.maxlen})\n",
    "\n",
    "      for attr in [\"action_mask\", \"action_mask_batch\"]:\n",
    "          agent_dict[\"agent_params\"].update({attr: getattr(self, attr).tolist()})\n",
    "\n",
    "      agent_dict[\"agent_params\"].update({\"memory\": list(self.memory)})\n",
    "\n",
    "      for tf_config in [\n",
    "          \"tf_config_intra_threads\",\n",
    "          \"tf_config_inter_threads\",\n",
    "          \"tf_config_soft_placement\",\n",
    "          \"tf_config_allow_growth\",\n",
    "      ]:\n",
    "          agent_dict[\"tf_config\"].update({tf_config: getattr(self, tf_config)})\n",
    "\n",
    "      with open(os.path.join(target_path, \"agent.json\"), \"w\") as f:\n",
    "          json.dump(agent_dict, f)\n",
    "\n",
    "      self.model.save_weights(os.path.join(target_path, \"model.h5\"))\n",
    "      self.target_model.save_weights(os.path.join(target_path, \"target_model.h5\"))\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: str) -> \"AbstractDQNAgent\":\n",
    "      \"\"\"\n",
    "        Loads the serialized state of a DQNAgent and returns an instance of it.\n",
    "      \"\"\"\n",
    "\n",
    "      with open(os.path.join(path, \"agent.json\"), \"r\") as f:\n",
    "          agent_dict = json.load(f)\n",
    "\n",
    "      agent = cls(**agent_dict[\"agent_init\"])\n",
    "\n",
    "      agent.action_mask = np.array(agent_dict[\"agent_params\"][\"action_mask\"])\n",
    "      agent.action_mask_batch = np.array(agent_dict[\"agent_params\"][\"action_mask_batch\"])\n",
    "\n",
    "      config = tf.compat.v1.ConfigProto(\n",
    "          intra_op_parallelism_threads=agent_dict[\"tf_config\"][\"tf_config_intra_threads\"],\n",
    "          inter_op_parallelism_threads=agent_dict[\"tf_config\"][\"tf_config_inter_threads\"],\n",
    "          allow_soft_placement=agent_dict[\"tf_config\"][\"tf_config_soft_placement\"])\n",
    "\n",
    "      config.gpu_options.allow_growth = agent_dict[\"tf_config\"][\"tf_config_allow_growth\"]\n",
    "      session = tf.compat.v1.Session(config=config)\n",
    "      set_session(session)\n",
    "\n",
    "      agent.model.load_weights('model.h5')\n",
    "      agent.target_model.load_weights(\"target_model.h5\")\n",
    "\n",
    "      return agent\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, experience):\n",
    "      raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def act(self, state):\n",
    "      raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def _build_model(self) -> Model:\n",
    "      raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efDYrUf9ZE--"
   },
   "source": [
    "## Deep Q-Learning Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-06T19:49:55.487943Z",
     "iopub.status.busy": "2023-01-06T19:49:55.487306Z",
     "iopub.status.idle": "2023-01-06T19:49:55.807979Z",
     "shell.execute_reply": "2023-01-06T19:49:55.806905Z",
     "shell.execute_reply.started": "2023-01-06T19:49:55.487912Z"
    },
    "id": "qADJ-_MoZE--",
    "outputId": "1bd87456-97fa-4795-fa7b-0dd1272ad3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoopResetEnv (max 30) wrapper is used.\n",
      "MaxAndSkipEnv (skip 4) wrapper is used.\n",
      "EpisodicLifeEnv wrapper is used.\n",
      "FireResetEnv wrapper is used.\n",
      "ClipRewardEnv wrapper is used.\n",
      "FrameStack (4) wrapper is used.\n"
     ]
    }
   ],
   "source": [
    "env = make_atari(\"VideoPinball-v4\")\n",
    "env = wrap_deepmind(env, frame_stack=True) # maps frames to 84x84x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5v-6xVSZE--"
   },
   "source": [
    "### Create the DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yO2DzOVAZE-_"
   },
   "source": [
    "Take the given `AbstractDQNAgent` (previously called `DQNAgent`) and add missing methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T19:49:55.809779Z",
     "iopub.status.busy": "2023-01-06T19:49:55.809506Z",
     "iopub.status.idle": "2023-01-06T19:49:55.830618Z",
     "shell.execute_reply": "2023-01-06T19:49:55.829246Z",
     "shell.execute_reply.started": "2023-01-06T19:49:55.809754Z"
    },
    "id": "I9nQIr7xZE-_"
   },
   "outputs": [],
   "source": [
    "class DQNAgent(AbstractDQNAgent):\n",
    "    def _build_model(self) -> Model:\n",
    "        \"\"\"Deep Q-network as defined in the DeepMind article on Nature\n",
    "        \n",
    "        Returns:\n",
    "            Model: Tensorflow Model which will be used as internal deep neural network\n",
    "        \"\"\"\n",
    "\n",
    "        atari_shape = (84, 84, 4)\n",
    "\n",
    "        # Frames from the observation\n",
    "        frames_input = Input(atari_shape, name=\"frames\")\n",
    "\n",
    "        # Actions as input\n",
    "        action_mask = Input((self.action_size,), name=\"action_mask\")\n",
    "\n",
    "        # Normalize the frames from [0, 255] to [0, 1]\n",
    "        normalized = Lambda(lambda x: x / 255.0, name=\"normalization\")(frames_input)\n",
    "\n",
    "        # \"The first hidden layer convolves 16 8×8 filters with stride 4 with the \n",
    "        # input image and applies a rectifier nonlinearity.\"\n",
    "        # Results in an output shape of (20, 20, 16)\n",
    "        conv1 = Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(8, 8),\n",
    "            strides=(4, 4),\n",
    "            activation=\"relu\"\n",
    "        )(normalized)\n",
    "\n",
    "        # \"The second hidden layer convolves 32 4×4 filters with stride 2, again followed \n",
    "        # by a rectifier nonlinearity.\" \n",
    "        # Results in an output shape of (9, 9, 32)\n",
    "        conv2 = Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(4,4),\n",
    "            strides=(2,2),\n",
    "            activation=\"relu\"\n",
    "        )(conv1)\n",
    "\n",
    "        conv3 = Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(4,4),\n",
    "            strides=(1,1),\n",
    "            activation=\"relu\"\n",
    "        )(conv2)\n",
    "\n",
    "        # Flattening the last convolutional layer.\n",
    "        conv_flattened = Flatten()(conv3)\n",
    "\n",
    "        # \"The final hidden layer is fully-connected and consists of 256 rectifier units.\"\n",
    "        hidden = Dense(units=512, activation='relu')(conv_flattened)\n",
    "\n",
    "        # \"The output layer is a fully-connected linear layer with a single output \n",
    "        # for each valid action.\"\n",
    "        output = Dense(self.action_size)(hidden)\n",
    "\n",
    "        # Multiply the output with the action mask to get only one action output\n",
    "        filtered_output = multiply([output, action_mask])\n",
    "\n",
    "        model = Model(inputs=[frames_input, action_mask], outputs=filtered_output)\n",
    "        model.compile(loss=huber_loss, optimizer=Adam(learning_rate=self.alpha), metrics=None)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def act(self, state: LazyFrames) -> int:\n",
    "        \"\"\"Selects the action to be executed based on the given state.\n",
    "\n",
    "        Implements epsilon greedy exploration strategy, i.e. with a probability of\n",
    "        epsilon, a random action is selected.\n",
    "\n",
    "        Args:\n",
    "            state [LazyFrames]: LazyFrames object representing the state based on 4 stacked observations (images)\n",
    "\n",
    "        Returns:\n",
    "            action [int]\n",
    "        \"\"\"\n",
    "\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            # ! TODO self.model.predict oder self.target_model.predict?\n",
    "            q_values = self.model.predict([[np.array(state)], self.action_mask])\n",
    "            action = np.argmax(q_values)\n",
    "        return action\n",
    "\n",
    "        \n",
    "    def train(self, experience: Tuple[LazyFrames, int, LazyFrames, float, bool]):\n",
    "        \"\"\"Stores the experience in memory. If memory is full trains network by replay.\n",
    "\n",
    "        Args:\n",
    "            experience [tuple]: Tuple of state, action, next state, reward, done.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        \n",
    "        self.memory.append(experience)\n",
    "        \n",
    "        #  - Update epsilon as long as it is not minimal\n",
    "        #  - Update weights of the target model (syn of the two models)\n",
    "        #  - Execute replay\n",
    "        if self.step >= self.start_replay_step:\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon -= self.epsilon_decay\n",
    "            if self.step % self.target_model_update_interval == 0:\n",
    "                self.target_model.set_weights(self.model.get_weights())\n",
    "            if self.step % self.train_freq == 0:\n",
    "                self._replay()\n",
    "\n",
    "        self.step += 1\n",
    "\n",
    "\n",
    "    def _replay(self) -> None:\n",
    "        \"\"\"Gets random experiences from memory for batch update of Q-function.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        states, actions, next_states, rewards, dones = [np.array(memory) for memory in zip(*sample(self.memory, self.batch_size))]\n",
    "\n",
    "        # ! Can be left out if useless\n",
    "        assert all(isinstance(x, np.ndarray) for x in (states, actions, rewards, next_states, dones)), \\\n",
    "            \"All experience batches should be of type np.ndarray.\"\n",
    "        assert states.shape == (self.batch_size, 84, 84, 4), \\\n",
    "            f\"States shape should be: {(self.batch_size, 84, 84, 4)}\"\n",
    "        assert actions.shape == (self.batch_size,), f\"Actions shape should be: {(self.batch_size,)}\"\n",
    "        assert rewards.shape == (self.batch_size,), f\"Rewards shape should be: {(self.batch_size,)}\"\n",
    "        assert next_states.shape == (self.batch_size, 84, 84, 4), \\\n",
    "            f\"Next states shape should be: {(self.batch_size, 84, 84, 4)}\"\n",
    "        assert dones.shape == (self.batch_size,), f\"Dones shape should be: {(self.batch_size,)}\"\n",
    "\n",
    "        # Predict the Q values of the next states. Passing ones as the action mask.\n",
    "        next_q_values = self.target_model.predict([next_states, self.action_mask_batch], verbose=0)\n",
    "\n",
    "        # Calculate the Q values.\n",
    "        # - Terminal states get the reward\n",
    "        # - Non-terminal states get reward + gamma * max next_state q_value\n",
    "        q_values = [reward + (1 - done) * self.gamma * np.max(next_q_value) for done, reward, next_q_value in zip(dones, rewards, next_q_values)]\n",
    "\n",
    "        # Create a one hot encoding of the actions (the selected action is 1 all others 0)\n",
    "        one_hot_actions = to_categorical(actions, num_classes=self.action_size)\n",
    "\n",
    "        # Create the target Q values based on the one hot encoding of the actions and the calculated Q values\n",
    "        # This can be seen as matrix multiplication\n",
    "        # q_values = [0.5, 0.7, 0.9]\n",
    "        # actions [[1. 0. 0. 0.]\n",
    "        #          [0. 0. 1. 0.]\n",
    "        #          [0. 0. 0. 1.]]\n",
    "        # output  [[0.5 0.  0.   0. ]\n",
    "        #          [0.  0.  0.7  0. ]\n",
    "        #          [0.  0.  0.9  0. ]]\n",
    "        target_q_values = np.array(q_values)[np.newaxis].T * one_hot_actions\n",
    "\n",
    "        # Fit the model with the given states and the selected actions as one hot vector and the target_q_values as y\n",
    "        self.model.fit(\n",
    "           x=[states, one_hot_actions],  # states and mask\n",
    "           y=target_q_values,  # target Q values\n",
    "           batch_size=self.batch_size,\n",
    "           verbose=0\n",
    "        )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T19:49:55.833024Z",
     "iopub.status.busy": "2023-01-06T19:49:55.832535Z",
     "iopub.status.idle": "2023-01-06T19:49:55.845710Z",
     "shell.execute_reply": "2023-01-06T19:49:55.844763Z",
     "shell.execute_reply.started": "2023-01-06T19:49:55.832996Z"
    },
    "id": "nkMxNKmAZE_A"
   },
   "outputs": [],
   "source": [
    "def interact_with_environment(env, agent, n_episodes=600, max_steps=1000000, train=True, verbose=True):      \n",
    "    statistics = []\n",
    "    tb_logger = TensorBoardLogger(f'./logs/run-{datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")}')\n",
    "    \n",
    "    with suppress(KeyboardInterrupt):\n",
    "        total_step = 0\n",
    "        for episode in range(n_episodes):\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            state = env.reset()\n",
    "            episode_start_time = time.time()\n",
    "            episode_step = 0\n",
    "\n",
    "            while not done:\n",
    "                action = agent.act(state)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "                if train:\n",
    "                    agent.train((state, action, next_state, reward, done))\n",
    "\n",
    "                if episode == 0:\n",
    "                    # for debug purpose log every state of first episode\n",
    "                    for obs in state:\n",
    "                        tb_logger.log_image(f'state_t{episode_step}:', tf_summary_image(np.array(obs, copy=False)),\n",
    "                                            global_step=total_step)\n",
    "                state = next_state\n",
    "                episode_reward += reward\n",
    "                episode_step += 1\n",
    "            \n",
    "            total_step += episode_step\n",
    "\n",
    "            if episode % 10 == 0:\n",
    "                speed = episode_step / (time.time() - episode_start_time)\n",
    "                tb_logger.log_scalar('score', episode_reward, global_step=total_step)\n",
    "                tb_logger.log_scalar('epsilon', agent.epsilon, global_step=total_step)\n",
    "                tb_logger.log_scalar('speed', speed, global_step=total_step)\n",
    "                if verbose:\n",
    "                    print(f'episode: {episode}/{n_episodes}, score: {episode_reward}, steps: {episode_step}, '\n",
    "                          f'total steps: {total_step}, e: {agent.epsilon:.3f}, speed: {speed:.2f} steps/s')\n",
    "\n",
    "            statistics.append({\n",
    "                'episode': episode,\n",
    "                'score': episode_reward,\n",
    "                'steps': episode_step\n",
    "            })\n",
    "                                  \n",
    "            if total_step >= max_steps:\n",
    "                break\n",
    "        \n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-06T19:49:55.847843Z",
     "iopub.status.busy": "2023-01-06T19:49:55.847536Z",
     "iopub.status.idle": "2023-01-06T23:22:55.177375Z",
     "shell.execute_reply": "2023-01-06T23:22:55.176328Z",
     "shell.execute_reply.started": "2023-01-06T19:49:55.847816Z"
    },
    "id": "Ae5vkyyHZE_A",
    "outputId": "165e0373-e37a-4b60-dcc8-678d83f9b16e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/10000, score: 10.0, steps: 78, total steps: 78, e: 1.000, speed: 111.95 steps/s\n",
      "episode: 10/10000, score: 36.0, steps: 254, total steps: 2063, e: 1.000, speed: 237.13 steps/s\n",
      "episode: 20/10000, score: 11.0, steps: 165, total steps: 3376, e: 1.000, speed: 233.65 steps/s\n",
      "episode: 30/10000, score: 24.0, steps: 168, total steps: 5241, e: 1.000, speed: 248.40 steps/s\n",
      "episode: 40/10000, score: 22.0, steps: 191, total steps: 6859, e: 1.000, speed: 236.66 steps/s\n",
      "episode: 50/10000, score: 1.0, steps: 108, total steps: 8238, e: 1.000, speed: 241.17 steps/s\n",
      "episode: 60/10000, score: 17.0, steps: 145, total steps: 10209, e: 1.000, speed: 244.90 steps/s\n",
      "episode: 70/10000, score: 7.0, steps: 58, total steps: 11834, e: 1.000, speed: 236.42 steps/s\n",
      "episode: 80/10000, score: 0.0, steps: 71, total steps: 13199, e: 1.000, speed: 247.26 steps/s\n",
      "episode: 90/10000, score: 8.0, steps: 91, total steps: 15116, e: 1.000, speed: 235.36 steps/s\n",
      "episode: 100/10000, score: 8.0, steps: 197, total steps: 16958, e: 1.000, speed: 239.29 steps/s\n",
      "episode: 110/10000, score: 16.0, steps: 179, total steps: 18229, e: 1.000, speed: 241.57 steps/s\n",
      "episode: 120/10000, score: 27.0, steps: 165, total steps: 19859, e: 1.000, speed: 237.72 steps/s\n",
      "episode: 130/10000, score: 0.0, steps: 65, total steps: 21721, e: 1.000, speed: 221.97 steps/s\n",
      "episode: 140/10000, score: 16.0, steps: 118, total steps: 23130, e: 1.000, speed: 243.73 steps/s\n",
      "episode: 150/10000, score: 18.0, steps: 151, total steps: 25092, e: 1.000, speed: 228.04 steps/s\n",
      "episode: 160/10000, score: 33.0, steps: 278, total steps: 26461, e: 1.000, speed: 241.41 steps/s\n",
      "episode: 170/10000, score: 1.0, steps: 36, total steps: 27937, e: 1.000, speed: 237.35 steps/s\n",
      "episode: 180/10000, score: 13.0, steps: 160, total steps: 30012, e: 1.000, speed: 239.73 steps/s\n",
      "episode: 190/10000, score: 14.0, steps: 284, total steps: 32333, e: 1.000, speed: 226.15 steps/s\n",
      "episode: 200/10000, score: 43.0, steps: 370, total steps: 34003, e: 1.000, speed: 241.13 steps/s\n",
      "episode: 210/10000, score: 1.0, steps: 151, total steps: 35743, e: 1.000, speed: 241.01 steps/s\n",
      "episode: 220/10000, score: 26.0, steps: 179, total steps: 36936, e: 1.000, speed: 242.14 steps/s\n",
      "episode: 230/10000, score: 17.0, steps: 196, total steps: 38963, e: 1.000, speed: 240.37 steps/s\n",
      "episode: 240/10000, score: 22.0, steps: 195, total steps: 41137, e: 1.000, speed: 238.12 steps/s\n",
      "episode: 250/10000, score: 25.0, steps: 204, total steps: 42763, e: 1.000, speed: 240.60 steps/s\n",
      "episode: 260/10000, score: 84.0, steps: 490, total steps: 44967, e: 1.000, speed: 240.28 steps/s\n",
      "episode: 270/10000, score: 0.0, steps: 39, total steps: 46406, e: 1.000, speed: 233.46 steps/s\n",
      "episode: 280/10000, score: 57.0, steps: 347, total steps: 48046, e: 1.000, speed: 241.36 steps/s\n",
      "episode: 290/10000, score: 0.0, steps: 157, total steps: 50120, e: 1.000, speed: 239.56 steps/s\n",
      "episode: 300/10000, score: 10.0, steps: 57, total steps: 52032, e: 1.000, speed: 243.59 steps/s\n",
      "episode: 310/10000, score: 64.0, steps: 407, total steps: 53791, e: 1.000, speed: 240.94 steps/s\n",
      "episode: 320/10000, score: 18.0, steps: 159, total steps: 55888, e: 1.000, speed: 246.96 steps/s\n",
      "episode: 330/10000, score: 5.0, steps: 47, total steps: 57539, e: 1.000, speed: 232.76 steps/s\n",
      "episode: 340/10000, score: 132.0, steps: 806, total steps: 60299, e: 1.000, speed: 239.55 steps/s\n",
      "episode: 350/10000, score: 13.0, steps: 131, total steps: 62005, e: 1.000, speed: 243.40 steps/s\n",
      "episode: 360/10000, score: 10.0, steps: 70, total steps: 63474, e: 1.000, speed: 244.06 steps/s\n",
      "episode: 370/10000, score: 99.0, steps: 534, total steps: 65111, e: 1.000, speed: 238.74 steps/s\n",
      "episode: 380/10000, score: 14.0, steps: 177, total steps: 67338, e: 1.000, speed: 242.86 steps/s\n",
      "episode: 390/10000, score: 29.0, steps: 253, total steps: 69145, e: 1.000, speed: 237.25 steps/s\n",
      "episode: 400/10000, score: 30.0, steps: 265, total steps: 71152, e: 1.000, speed: 237.88 steps/s\n",
      "episode: 410/10000, score: 5.0, steps: 35, total steps: 72560, e: 1.000, speed: 236.09 steps/s\n",
      "episode: 420/10000, score: 1.0, steps: 150, total steps: 73834, e: 1.000, speed: 240.58 steps/s\n",
      "episode: 430/10000, score: 13.0, steps: 119, total steps: 75351, e: 1.000, speed: 242.10 steps/s\n",
      "episode: 440/10000, score: 8.0, steps: 89, total steps: 76744, e: 1.000, speed: 245.58 steps/s\n",
      "episode: 450/10000, score: 13.0, steps: 164, total steps: 78143, e: 1.000, speed: 245.34 steps/s\n",
      "episode: 460/10000, score: 10.0, steps: 90, total steps: 79626, e: 1.000, speed: 224.89 steps/s\n",
      "episode: 470/10000, score: 24.0, steps: 145, total steps: 81639, e: 1.000, speed: 242.84 steps/s\n",
      "episode: 480/10000, score: 14.0, steps: 164, total steps: 82915, e: 1.000, speed: 243.70 steps/s\n",
      "episode: 490/10000, score: 35.0, steps: 188, total steps: 85060, e: 1.000, speed: 231.30 steps/s\n",
      "episode: 500/10000, score: 14.0, steps: 89, total steps: 86988, e: 1.000, speed: 239.31 steps/s\n",
      "episode: 510/10000, score: 31.0, steps: 185, total steps: 88239, e: 1.000, speed: 241.07 steps/s\n",
      "episode: 520/10000, score: 6.0, steps: 142, total steps: 89959, e: 1.000, speed: 234.82 steps/s\n",
      "episode: 530/10000, score: 5.0, steps: 189, total steps: 91495, e: 1.000, speed: 240.63 steps/s\n",
      "episode: 540/10000, score: 13.0, steps: 96, total steps: 93129, e: 1.000, speed: 240.32 steps/s\n",
      "episode: 550/10000, score: 0.0, steps: 79, total steps: 94992, e: 1.000, speed: 237.92 steps/s\n",
      "episode: 560/10000, score: 16.0, steps: 187, total steps: 96533, e: 1.000, speed: 237.93 steps/s\n",
      "episode: 570/10000, score: 19.0, steps: 75, total steps: 97778, e: 1.000, speed: 228.14 steps/s\n",
      "episode: 580/10000, score: 1.0, steps: 62, total steps: 99836, e: 1.000, speed: 242.19 steps/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 590/10000, score: 5.0, steps: 108, total steps: 101114, e: 0.996, speed: 81.39 steps/s\n",
      "episode: 600/10000, score: 38.0, steps: 221, total steps: 102941, e: 0.988, speed: 82.63 steps/s\n",
      "episode: 610/10000, score: 16.0, steps: 104, total steps: 104852, e: 0.981, speed: 83.82 steps/s\n",
      "episode: 620/10000, score: 1.0, steps: 166, total steps: 107154, e: 0.971, speed: 89.82 steps/s\n",
      "episode: 630/10000, score: 15.0, steps: 141, total steps: 110077, e: 0.960, speed: 84.72 steps/s\n",
      "episode: 640/10000, score: 89.0, steps: 605, total steps: 112019, e: 0.952, speed: 86.86 steps/s\n",
      "episode: 650/10000, score: 11.0, steps: 108, total steps: 113841, e: 0.945, speed: 89.10 steps/s\n",
      "episode: 660/10000, score: 31.0, steps: 384, total steps: 115789, e: 0.937, speed: 89.66 steps/s\n",
      "episode: 670/10000, score: 41.0, steps: 271, total steps: 142385, e: 0.830, speed: 87.37 steps/s\n",
      "episode: 680/10000, score: 10.0, steps: 144, total steps: 144059, e: 0.824, speed: 86.15 steps/s\n",
      "episode: 690/10000, score: 4.0, steps: 175, total steps: 145909, e: 0.816, speed: 88.52 steps/s\n",
      "episode: 700/10000, score: 4.0, steps: 230, total steps: 148045, e: 0.808, speed: 86.97 steps/s\n",
      "episode: 710/10000, score: 8.0, steps: 137, total steps: 149285, e: 0.803, speed: 81.20 steps/s\n",
      "episode: 720/10000, score: 8.0, steps: 126, total steps: 150947, e: 0.796, speed: 85.88 steps/s\n",
      "episode: 730/10000, score: 22.0, steps: 173, total steps: 152136, e: 0.791, speed: 85.42 steps/s\n",
      "episode: 740/10000, score: 61.0, steps: 532, total steps: 154315, e: 0.783, speed: 85.37 steps/s\n",
      "episode: 750/10000, score: 39.0, steps: 277, total steps: 156076, e: 0.776, speed: 85.02 steps/s\n",
      "episode: 760/10000, score: 41.0, steps: 256, total steps: 157840, e: 0.769, speed: 77.99 steps/s\n",
      "episode: 770/10000, score: 8.0, steps: 112, total steps: 158908, e: 0.764, speed: 86.94 steps/s\n",
      "episode: 780/10000, score: 32.0, steps: 313, total steps: 161258, e: 0.755, speed: 86.21 steps/s\n",
      "episode: 790/10000, score: 3.0, steps: 57, total steps: 162403, e: 0.750, speed: 82.49 steps/s\n",
      "episode: 800/10000, score: 21.0, steps: 152, total steps: 163985, e: 0.744, speed: 88.61 steps/s\n",
      "episode: 810/10000, score: 4.0, steps: 41, total steps: 165054, e: 0.740, speed: 91.84 steps/s\n",
      "episode: 820/10000, score: 11.0, steps: 157, total steps: 166618, e: 0.734, speed: 83.22 steps/s\n",
      "episode: 830/10000, score: 106.0, steps: 626, total steps: 168605, e: 0.726, speed: 85.11 steps/s\n",
      "episode: 840/10000, score: 4.0, steps: 113, total steps: 170056, e: 0.720, speed: 84.71 steps/s\n",
      "episode: 850/10000, score: 13.0, steps: 198, total steps: 171707, e: 0.713, speed: 82.12 steps/s\n",
      "episode: 860/10000, score: 33.0, steps: 267, total steps: 173682, e: 0.705, speed: 84.97 steps/s\n",
      "episode: 870/10000, score: 4.0, steps: 142, total steps: 174706, e: 0.701, speed: 79.19 steps/s\n",
      "episode: 880/10000, score: 10.0, steps: 158, total steps: 176013, e: 0.696, speed: 83.41 steps/s\n",
      "episode: 890/10000, score: 77.0, steps: 473, total steps: 177950, e: 0.688, speed: 82.21 steps/s\n",
      "episode: 900/10000, score: 3.0, steps: 53, total steps: 179449, e: 0.682, speed: 82.40 steps/s\n",
      "episode: 910/10000, score: 5.0, steps: 52, total steps: 180848, e: 0.677, speed: 83.05 steps/s\n",
      "episode: 920/10000, score: 4.0, steps: 106, total steps: 182364, e: 0.671, speed: 80.03 steps/s\n",
      "episode: 930/10000, score: 5.0, steps: 90, total steps: 183368, e: 0.667, speed: 82.76 steps/s\n",
      "episode: 940/10000, score: 1.0, steps: 28, total steps: 184511, e: 0.662, speed: 77.54 steps/s\n",
      "episode: 950/10000, score: 6.0, steps: 34, total steps: 185840, e: 0.657, speed: 88.03 steps/s\n",
      "episode: 960/10000, score: 3.0, steps: 83, total steps: 186967, e: 0.652, speed: 83.59 steps/s\n",
      "episode: 970/10000, score: 3.0, steps: 37, total steps: 188505, e: 0.646, speed: 73.74 steps/s\n",
      "episode: 980/10000, score: 10.0, steps: 61, total steps: 190544, e: 0.638, speed: 83.50 steps/s\n",
      "episode: 990/10000, score: 0.0, steps: 86, total steps: 192001, e: 0.632, speed: 78.32 steps/s\n",
      "episode: 1000/10000, score: 1.0, steps: 102, total steps: 193057, e: 0.628, speed: 77.87 steps/s\n",
      "episode: 1010/10000, score: 22.0, steps: 259, total steps: 194599, e: 0.622, speed: 82.47 steps/s\n",
      "episode: 1020/10000, score: 24.0, steps: 222, total steps: 195862, e: 0.617, speed: 83.57 steps/s\n",
      "episode: 1030/10000, score: 31.0, steps: 228, total steps: 197638, e: 0.609, speed: 78.78 steps/s\n",
      "episode: 1040/10000, score: 0.0, steps: 119, total steps: 199021, e: 0.604, speed: 80.73 steps/s\n",
      "episode: 1050/10000, score: 23.0, steps: 204, total steps: 200334, e: 0.599, speed: 83.59 steps/s\n",
      "episode: 1060/10000, score: 2.0, steps: 99, total steps: 201642, e: 0.593, speed: 81.10 steps/s\n",
      "episode: 1070/10000, score: 14.0, steps: 91, total steps: 202613, e: 0.590, speed: 78.53 steps/s\n",
      "episode: 1080/10000, score: 3.0, steps: 143, total steps: 204560, e: 0.582, speed: 78.75 steps/s\n",
      "episode: 1090/10000, score: 18.0, steps: 115, total steps: 205808, e: 0.577, speed: 83.87 steps/s\n",
      "episode: 1100/10000, score: 59.0, steps: 313, total steps: 207210, e: 0.571, speed: 78.57 steps/s\n",
      "episode: 1110/10000, score: 0.0, steps: 114, total steps: 207984, e: 0.568, speed: 81.12 steps/s\n",
      "episode: 1120/10000, score: 0.0, steps: 61, total steps: 209398, e: 0.562, speed: 78.97 steps/s\n",
      "episode: 1130/10000, score: 1.0, steps: 84, total steps: 210848, e: 0.557, speed: 82.97 steps/s\n",
      "episode: 1140/10000, score: 0.0, steps: 48, total steps: 211766, e: 0.553, speed: 77.58 steps/s\n",
      "episode: 1150/10000, score: 8.0, steps: 87, total steps: 212986, e: 0.548, speed: 82.50 steps/s\n",
      "episode: 1160/10000, score: 10.0, steps: 143, total steps: 214630, e: 0.541, speed: 80.41 steps/s\n",
      "episode: 1170/10000, score: 8.0, steps: 105, total steps: 215944, e: 0.536, speed: 84.16 steps/s\n",
      "episode: 1180/10000, score: 7.0, steps: 28, total steps: 216931, e: 0.532, speed: 78.18 steps/s\n",
      "episode: 1190/10000, score: 8.0, steps: 194, total steps: 218240, e: 0.527, speed: 81.24 steps/s\n",
      "episode: 1200/10000, score: 33.0, steps: 243, total steps: 219732, e: 0.521, speed: 78.74 steps/s\n",
      "episode: 1210/10000, score: 11.0, steps: 117, total steps: 221093, e: 0.516, speed: 84.49 steps/s\n",
      "episode: 1220/10000, score: 6.0, steps: 36, total steps: 222232, e: 0.511, speed: 85.60 steps/s\n",
      "episode: 1230/10000, score: 8.0, steps: 140, total steps: 223673, e: 0.505, speed: 75.46 steps/s\n",
      "episode: 1240/10000, score: 15.0, steps: 201, total steps: 225445, e: 0.498, speed: 79.93 steps/s\n",
      "episode: 1250/10000, score: 9.0, steps: 79, total steps: 227488, e: 0.490, speed: 81.97 steps/s\n",
      "episode: 1260/10000, score: 18.0, steps: 356, total steps: 228729, e: 0.485, speed: 79.38 steps/s\n",
      "episode: 1270/10000, score: 0.0, steps: 19, total steps: 229913, e: 0.480, speed: 77.31 steps/s\n",
      "episode: 1280/10000, score: 7.0, steps: 85, total steps: 230946, e: 0.476, speed: 77.18 steps/s\n",
      "episode: 1290/10000, score: 17.0, steps: 133, total steps: 232006, e: 0.472, speed: 77.54 steps/s\n",
      "episode: 1300/10000, score: 19.0, steps: 182, total steps: 233513, e: 0.466, speed: 76.80 steps/s\n",
      "episode: 1310/10000, score: 2.0, steps: 30, total steps: 234342, e: 0.463, speed: 74.91 steps/s\n",
      "episode: 1320/10000, score: 1.0, steps: 73, total steps: 235387, e: 0.458, speed: 78.68 steps/s\n",
      "episode: 1330/10000, score: 7.0, steps: 121, total steps: 236603, e: 0.454, speed: 80.17 steps/s\n",
      "episode: 1340/10000, score: 7.0, steps: 44, total steps: 237744, e: 0.449, speed: 75.69 steps/s\n",
      "episode: 1350/10000, score: 1.0, steps: 56, total steps: 239197, e: 0.443, speed: 81.59 steps/s\n",
      "episode: 1360/10000, score: 35.0, steps: 427, total steps: 240687, e: 0.437, speed: 79.51 steps/s\n",
      "episode: 1370/10000, score: 0.0, steps: 59, total steps: 243243, e: 0.427, speed: 73.05 steps/s\n",
      "episode: 1380/10000, score: 37.0, steps: 298, total steps: 244744, e: 0.421, speed: 79.75 steps/s\n",
      "episode: 1390/10000, score: 1.0, steps: 115, total steps: 246175, e: 0.415, speed: 77.11 steps/s\n",
      "episode: 1400/10000, score: 18.0, steps: 247, total steps: 247626, e: 0.409, speed: 78.34 steps/s\n",
      "episode: 1410/10000, score: 3.0, steps: 112, total steps: 249004, e: 0.404, speed: 77.35 steps/s\n",
      "episode: 1420/10000, score: 2.0, steps: 59, total steps: 250300, e: 0.399, speed: 86.24 steps/s\n",
      "episode: 1430/10000, score: 2.0, steps: 36, total steps: 251817, e: 0.393, speed: 77.53 steps/s\n",
      "episode: 1440/10000, score: 17.0, steps: 136, total steps: 252961, e: 0.388, speed: 81.24 steps/s\n",
      "episode: 1450/10000, score: 1.0, steps: 23, total steps: 254139, e: 0.383, speed: 76.84 steps/s\n",
      "episode: 1460/10000, score: 3.0, steps: 31, total steps: 255324, e: 0.379, speed: 86.78 steps/s\n",
      "episode: 1470/10000, score: 24.0, steps: 193, total steps: 256823, e: 0.373, speed: 77.48 steps/s\n",
      "episode: 1480/10000, score: 0.0, steps: 113, total steps: 257913, e: 0.368, speed: 77.12 steps/s\n",
      "episode: 1490/10000, score: 7.0, steps: 107, total steps: 259284, e: 0.363, speed: 75.35 steps/s\n",
      "episode: 1500/10000, score: 2.0, steps: 364, total steps: 260779, e: 0.357, speed: 76.41 steps/s\n",
      "episode: 1510/10000, score: 19.0, steps: 144, total steps: 262000, e: 0.352, speed: 78.03 steps/s\n",
      "episode: 1520/10000, score: 14.0, steps: 153, total steps: 263304, e: 0.347, speed: 83.05 steps/s\n",
      "episode: 1530/10000, score: 11.0, steps: 88, total steps: 264399, e: 0.342, speed: 80.49 steps/s\n",
      "episode: 1540/10000, score: 13.0, steps: 94, total steps: 265559, e: 0.338, speed: 78.52 steps/s\n",
      "episode: 1550/10000, score: 4.0, steps: 76, total steps: 266401, e: 0.334, speed: 78.42 steps/s\n",
      "episode: 1560/10000, score: 10.0, steps: 99, total steps: 267459, e: 0.330, speed: 70.63 steps/s\n",
      "episode: 1570/10000, score: 3.0, steps: 29, total steps: 268591, e: 0.326, speed: 74.40 steps/s\n",
      "episode: 1580/10000, score: 0.0, steps: 59, total steps: 269957, e: 0.320, speed: 68.85 steps/s\n",
      "episode: 1590/10000, score: 28.0, steps: 327, total steps: 271475, e: 0.314, speed: 71.61 steps/s\n",
      "episode: 1600/10000, score: 6.0, steps: 67, total steps: 272642, e: 0.309, speed: 74.64 steps/s\n",
      "episode: 1610/10000, score: 4.0, steps: 74, total steps: 273809, e: 0.305, speed: 76.34 steps/s\n",
      "episode: 1620/10000, score: 18.0, steps: 114, total steps: 275453, e: 0.298, speed: 75.89 steps/s\n",
      "episode: 1630/10000, score: 1.0, steps: 186, total steps: 276985, e: 0.292, speed: 77.23 steps/s\n",
      "episode: 1640/10000, score: 16.0, steps: 153, total steps: 278051, e: 0.288, speed: 73.58 steps/s\n",
      "episode: 1650/10000, score: 0.0, steps: 84, total steps: 279308, e: 0.283, speed: 71.57 steps/s\n",
      "episode: 1660/10000, score: 4.0, steps: 162, total steps: 280447, e: 0.278, speed: 73.14 steps/s\n",
      "episode: 1670/10000, score: 0.0, steps: 143, total steps: 281551, e: 0.274, speed: 73.25 steps/s\n",
      "episode: 1680/10000, score: 6.0, steps: 199, total steps: 282707, e: 0.269, speed: 69.59 steps/s\n",
      "episode: 1690/10000, score: 0.0, steps: 90, total steps: 283543, e: 0.266, speed: 79.33 steps/s\n",
      "episode: 1700/10000, score: 0.0, steps: 67, total steps: 284495, e: 0.262, speed: 71.11 steps/s\n",
      "episode: 1710/10000, score: 4.0, steps: 98, total steps: 285419, e: 0.258, speed: 75.34 steps/s\n",
      "episode: 1720/10000, score: 11.0, steps: 74, total steps: 286598, e: 0.254, speed: 76.09 steps/s\n",
      "episode: 1730/10000, score: 15.0, steps: 159, total steps: 288382, e: 0.246, speed: 73.58 steps/s\n",
      "episode: 1740/10000, score: 2.0, steps: 38, total steps: 289388, e: 0.242, speed: 77.90 steps/s\n",
      "episode: 1750/10000, score: 0.0, steps: 86, total steps: 291088, e: 0.236, speed: 68.59 steps/s\n",
      "episode: 1760/10000, score: 1.0, steps: 117, total steps: 292237, e: 0.231, speed: 75.52 steps/s\n",
      "episode: 1770/10000, score: 5.0, steps: 130, total steps: 293701, e: 0.225, speed: 70.63 steps/s\n",
      "episode: 1780/10000, score: 4.0, steps: 105, total steps: 294890, e: 0.220, speed: 75.42 steps/s\n",
      "episode: 1790/10000, score: 5.0, steps: 31, total steps: 296152, e: 0.215, speed: 72.00 steps/s\n",
      "episode: 1800/10000, score: 1.0, steps: 34, total steps: 297158, e: 0.211, speed: 67.72 steps/s\n",
      "episode: 1810/10000, score: 5.0, steps: 189, total steps: 298941, e: 0.204, speed: 72.19 steps/s\n",
      "episode: 1820/10000, score: 18.0, steps: 152, total steps: 300225, e: 0.199, speed: 73.77 steps/s\n",
      "episode: 1830/10000, score: 2.0, steps: 87, total steps: 301465, e: 0.194, speed: 72.69 steps/s\n",
      "episode: 1840/10000, score: 0.0, steps: 47, total steps: 302461, e: 0.190, speed: 72.69 steps/s\n",
      "episode: 1850/10000, score: 29.0, steps: 274, total steps: 303638, e: 0.185, speed: 73.94 steps/s\n",
      "episode: 1860/10000, score: 34.0, steps: 224, total steps: 305147, e: 0.179, speed: 71.95 steps/s\n",
      "episode: 1870/10000, score: 8.0, steps: 161, total steps: 306237, e: 0.175, speed: 72.24 steps/s\n",
      "episode: 1880/10000, score: 24.0, steps: 295, total steps: 307586, e: 0.170, speed: 71.60 steps/s\n",
      "episode: 1890/10000, score: 16.0, steps: 92, total steps: 308789, e: 0.165, speed: 67.17 steps/s\n",
      "episode: 1900/10000, score: 2.0, steps: 64, total steps: 310531, e: 0.158, speed: 71.75 steps/s\n",
      "episode: 1910/10000, score: 9.0, steps: 81, total steps: 311708, e: 0.153, speed: 69.75 steps/s\n",
      "episode: 1920/10000, score: 15.0, steps: 98, total steps: 313196, e: 0.147, speed: 70.78 steps/s\n",
      "episode: 1930/10000, score: 1.0, steps: 73, total steps: 314158, e: 0.143, speed: 75.52 steps/s\n",
      "episode: 1940/10000, score: 23.0, steps: 332, total steps: 315423, e: 0.138, speed: 72.73 steps/s\n",
      "episode: 1950/10000, score: 6.0, steps: 33, total steps: 317414, e: 0.130, speed: 69.96 steps/s\n",
      "episode: 1960/10000, score: 24.0, steps: 166, total steps: 318448, e: 0.126, speed: 74.61 steps/s\n",
      "episode: 1970/10000, score: 2.0, steps: 25, total steps: 319545, e: 0.122, speed: 72.37 steps/s\n",
      "episode: 1980/10000, score: 18.0, steps: 311, total steps: 320731, e: 0.117, speed: 73.83 steps/s\n",
      "episode: 1990/10000, score: 2.0, steps: 18, total steps: 321369, e: 0.115, speed: 66.45 steps/s\n",
      "episode: 2000/10000, score: 24.0, steps: 131, total steps: 322691, e: 0.109, speed: 73.44 steps/s\n",
      "episode: 2010/10000, score: 8.0, steps: 130, total steps: 323780, e: 0.105, speed: 71.96 steps/s\n",
      "episode: 2020/10000, score: 0.0, steps: 22, total steps: 325853, e: 0.097, speed: 75.65 steps/s\n",
      "episode: 2030/10000, score: 8.0, steps: 145, total steps: 326869, e: 0.093, speed: 72.40 steps/s\n",
      "episode: 2040/10000, score: 0.0, steps: 30, total steps: 328257, e: 0.087, speed: 69.35 steps/s\n",
      "episode: 2050/10000, score: 0.0, steps: 45, total steps: 329212, e: 0.083, speed: 73.96 steps/s\n",
      "episode: 2060/10000, score: 30.0, steps: 168, total steps: 330634, e: 0.077, speed: 72.91 steps/s\n",
      "episode: 2070/10000, score: 4.0, steps: 64, total steps: 332416, e: 0.070, speed: 65.34 steps/s\n",
      "episode: 2080/10000, score: 2.0, steps: 108, total steps: 333749, e: 0.065, speed: 69.58 steps/s\n",
      "episode: 2090/10000, score: 20.0, steps: 267, total steps: 335329, e: 0.059, speed: 68.59 steps/s\n",
      "episode: 2100/10000, score: 2.0, steps: 61, total steps: 336321, e: 0.055, speed: 68.44 steps/s\n",
      "episode: 2110/10000, score: 64.0, steps: 484, total steps: 337687, e: 0.049, speed: 71.08 steps/s\n",
      "episode: 2120/10000, score: 12.0, steps: 201, total steps: 339036, e: 0.044, speed: 69.47 steps/s\n",
      "episode: 2130/10000, score: 0.0, steps: 65, total steps: 340632, e: 0.037, speed: 67.83 steps/s\n",
      "episode: 2140/10000, score: 4.0, steps: 59, total steps: 342140, e: 0.031, speed: 70.52 steps/s\n",
      "episode: 2150/10000, score: 16.0, steps: 206, total steps: 343301, e: 0.027, speed: 70.41 steps/s\n",
      "episode: 2160/10000, score: 20.0, steps: 109, total steps: 344368, e: 0.023, speed: 69.65 steps/s\n",
      "episode: 2170/10000, score: 1.0, steps: 100, total steps: 345768, e: 0.017, speed: 69.28 steps/s\n",
      "episode: 2180/10000, score: 31.0, steps: 162, total steps: 347180, e: 0.011, speed: 67.00 steps/s\n",
      "episode: 2190/10000, score: 10.0, steps: 140, total steps: 348380, e: 0.010, speed: 71.53 steps/s\n",
      "episode: 2200/10000, score: 5.0, steps: 132, total steps: 349185, e: 0.010, speed: 65.62 steps/s\n",
      "episode: 2210/10000, score: 35.0, steps: 238, total steps: 350184, e: 0.010, speed: 69.46 steps/s\n",
      "episode: 2220/10000, score: 6.0, steps: 188, total steps: 351924, e: 0.010, speed: 72.07 steps/s\n",
      "episode: 2230/10000, score: 0.0, steps: 67, total steps: 353394, e: 0.010, speed: 69.48 steps/s\n",
      "episode: 2240/10000, score: 7.0, steps: 34, total steps: 354668, e: 0.010, speed: 72.95 steps/s\n",
      "episode: 2250/10000, score: 13.0, steps: 100, total steps: 356008, e: 0.010, speed: 72.70 steps/s\n",
      "episode: 2260/10000, score: 7.0, steps: 174, total steps: 357935, e: 0.010, speed: 71.53 steps/s\n",
      "episode: 2270/10000, score: 7.0, steps: 130, total steps: 359526, e: 0.010, speed: 68.90 steps/s\n",
      "episode: 2280/10000, score: 4.0, steps: 116, total steps: 360563, e: 0.010, speed: 71.67 steps/s\n",
      "episode: 2290/10000, score: 68.0, steps: 408, total steps: 362092, e: 0.010, speed: 70.19 steps/s\n",
      "episode: 2300/10000, score: 18.0, steps: 97, total steps: 362917, e: 0.010, speed: 69.65 steps/s\n",
      "episode: 2310/10000, score: 0.0, steps: 86, total steps: 364267, e: 0.010, speed: 68.96 steps/s\n",
      "episode: 2320/10000, score: 37.0, steps: 133, total steps: 365661, e: 0.010, speed: 72.35 steps/s\n",
      "episode: 2330/10000, score: 0.0, steps: 18, total steps: 366627, e: 0.010, speed: 75.82 steps/s\n",
      "episode: 2340/10000, score: 4.0, steps: 36, total steps: 368103, e: 0.010, speed: 72.91 steps/s\n",
      "episode: 2350/10000, score: 18.0, steps: 261, total steps: 369834, e: 0.010, speed: 71.78 steps/s\n",
      "episode: 2360/10000, score: 7.0, steps: 160, total steps: 371110, e: 0.010, speed: 71.28 steps/s\n",
      "episode: 2370/10000, score: 34.0, steps: 230, total steps: 372101, e: 0.010, speed: 65.76 steps/s\n",
      "episode: 2380/10000, score: 23.0, steps: 221, total steps: 373094, e: 0.010, speed: 71.29 steps/s\n",
      "episode: 2390/10000, score: 5.0, steps: 67, total steps: 374679, e: 0.010, speed: 70.27 steps/s\n",
      "episode: 2400/10000, score: 0.0, steps: 78, total steps: 375856, e: 0.010, speed: 72.57 steps/s\n",
      "episode: 2410/10000, score: 0.0, steps: 155, total steps: 376935, e: 0.010, speed: 70.61 steps/s\n",
      "episode: 2420/10000, score: 0.0, steps: 159, total steps: 378515, e: 0.010, speed: 72.00 steps/s\n",
      "episode: 2430/10000, score: 3.0, steps: 32, total steps: 379647, e: 0.010, speed: 68.71 steps/s\n",
      "episode: 2440/10000, score: 17.0, steps: 102, total steps: 380624, e: 0.010, speed: 64.32 steps/s\n",
      "episode: 2450/10000, score: 0.0, steps: 123, total steps: 381906, e: 0.010, speed: 71.49 steps/s\n",
      "episode: 2460/10000, score: 16.0, steps: 94, total steps: 383393, e: 0.010, speed: 70.64 steps/s\n",
      "episode: 2470/10000, score: 12.0, steps: 136, total steps: 384257, e: 0.010, speed: 73.08 steps/s\n",
      "episode: 2480/10000, score: 14.0, steps: 170, total steps: 386389, e: 0.010, speed: 69.96 steps/s\n",
      "episode: 2490/10000, score: 14.0, steps: 176, total steps: 388199, e: 0.010, speed: 70.69 steps/s\n",
      "episode: 2500/10000, score: 4.0, steps: 43, total steps: 389683, e: 0.010, speed: 68.06 steps/s\n",
      "episode: 2510/10000, score: 53.0, steps: 307, total steps: 391729, e: 0.010, speed: 69.33 steps/s\n",
      "episode: 2520/10000, score: 3.0, steps: 53, total steps: 393175, e: 0.010, speed: 73.17 steps/s\n",
      "episode: 2530/10000, score: 13.0, steps: 121, total steps: 394582, e: 0.010, speed: 72.53 steps/s\n",
      "episode: 2540/10000, score: 5.0, steps: 81, total steps: 395772, e: 0.010, speed: 70.06 steps/s\n",
      "episode: 2550/10000, score: 22.0, steps: 215, total steps: 396755, e: 0.010, speed: 72.55 steps/s\n",
      "episode: 2560/10000, score: 16.0, steps: 195, total steps: 398305, e: 0.010, speed: 71.19 steps/s\n",
      "episode: 2570/10000, score: 24.0, steps: 570, total steps: 399978, e: 0.010, speed: 71.53 steps/s\n",
      "episode: 2580/10000, score: 10.0, steps: 49, total steps: 401374, e: 0.010, speed: 70.53 steps/s\n",
      "episode: 2590/10000, score: 0.0, steps: 40, total steps: 403098, e: 0.010, speed: 72.81 steps/s\n",
      "episode: 2600/10000, score: 39.0, steps: 245, total steps: 404422, e: 0.010, speed: 71.31 steps/s\n",
      "episode: 2610/10000, score: 50.0, steps: 276, total steps: 405690, e: 0.010, speed: 68.55 steps/s\n",
      "episode: 2620/10000, score: 9.0, steps: 45, total steps: 407310, e: 0.010, speed: 70.84 steps/s\n",
      "episode: 2630/10000, score: 0.0, steps: 118, total steps: 408545, e: 0.010, speed: 70.36 steps/s\n",
      "episode: 2640/10000, score: 9.0, steps: 181, total steps: 411213, e: 0.010, speed: 70.29 steps/s\n",
      "episode: 2650/10000, score: 10.0, steps: 198, total steps: 412676, e: 0.010, speed: 70.97 steps/s\n",
      "episode: 2660/10000, score: 14.0, steps: 55, total steps: 413896, e: 0.010, speed: 68.80 steps/s\n",
      "episode: 2670/10000, score: 1.0, steps: 77, total steps: 415819, e: 0.010, speed: 60.90 steps/s\n",
      "episode: 2680/10000, score: 13.0, steps: 48, total steps: 417149, e: 0.010, speed: 65.40 steps/s\n",
      "episode: 2690/10000, score: 2.0, steps: 29, total steps: 418477, e: 0.010, speed: 67.49 steps/s\n",
      "episode: 2700/10000, score: 9.0, steps: 112, total steps: 419809, e: 0.010, speed: 72.48 steps/s\n",
      "episode: 2710/10000, score: 20.0, steps: 243, total steps: 421320, e: 0.010, speed: 70.39 steps/s\n",
      "episode: 2720/10000, score: 21.0, steps: 149, total steps: 423208, e: 0.010, speed: 70.36 steps/s\n",
      "episode: 2730/10000, score: 5.0, steps: 59, total steps: 424529, e: 0.010, speed: 73.01 steps/s\n",
      "episode: 2740/10000, score: 31.0, steps: 159, total steps: 425930, e: 0.010, speed: 70.74 steps/s\n",
      "episode: 2750/10000, score: 40.0, steps: 230, total steps: 427304, e: 0.010, speed: 70.00 steps/s\n",
      "episode: 2760/10000, score: 9.0, steps: 133, total steps: 429474, e: 0.010, speed: 71.36 steps/s\n",
      "episode: 2770/10000, score: 7.0, steps: 72, total steps: 431316, e: 0.010, speed: 73.29 steps/s\n",
      "episode: 2780/10000, score: 28.0, steps: 384, total steps: 433574, e: 0.010, speed: 71.07 steps/s\n",
      "episode: 2790/10000, score: 21.0, steps: 222, total steps: 435133, e: 0.010, speed: 65.32 steps/s\n",
      "episode: 2800/10000, score: 120.0, steps: 692, total steps: 437770, e: 0.010, speed: 69.68 steps/s\n",
      "episode: 2810/10000, score: 7.0, steps: 86, total steps: 439525, e: 0.010, speed: 67.85 steps/s\n",
      "episode: 2820/10000, score: 20.0, steps: 328, total steps: 441772, e: 0.010, speed: 68.56 steps/s\n",
      "episode: 2830/10000, score: 13.0, steps: 62, total steps: 443583, e: 0.010, speed: 71.07 steps/s\n",
      "episode: 2840/10000, score: 17.0, steps: 200, total steps: 445518, e: 0.010, speed: 68.67 steps/s\n",
      "episode: 2850/10000, score: 65.0, steps: 371, total steps: 446839, e: 0.010, speed: 71.54 steps/s\n",
      "episode: 2860/10000, score: 18.0, steps: 132, total steps: 448260, e: 0.010, speed: 71.90 steps/s\n",
      "episode: 2870/10000, score: 41.0, steps: 244, total steps: 450782, e: 0.010, speed: 70.85 steps/s\n",
      "episode: 2880/10000, score: 2.0, steps: 41, total steps: 452785, e: 0.010, speed: 68.07 steps/s\n",
      "episode: 2890/10000, score: 10.0, steps: 143, total steps: 454650, e: 0.010, speed: 71.02 steps/s\n",
      "episode: 2900/10000, score: 51.0, steps: 360, total steps: 457196, e: 0.010, speed: 67.24 steps/s\n",
      "episode: 2910/10000, score: 7.0, steps: 76, total steps: 459186, e: 0.010, speed: 67.48 steps/s\n",
      "episode: 2920/10000, score: 10.0, steps: 99, total steps: 461248, e: 0.010, speed: 71.25 steps/s\n",
      "episode: 2930/10000, score: 11.0, steps: 74, total steps: 463704, e: 0.010, speed: 70.84 steps/s\n",
      "episode: 2940/10000, score: 79.0, steps: 395, total steps: 466157, e: 0.010, speed: 70.89 steps/s\n",
      "episode: 2950/10000, score: 11.0, steps: 98, total steps: 468044, e: 0.010, speed: 69.23 steps/s\n",
      "episode: 2960/10000, score: 11.0, steps: 157, total steps: 470348, e: 0.010, speed: 72.06 steps/s\n",
      "episode: 2970/10000, score: 40.0, steps: 214, total steps: 472830, e: 0.010, speed: 69.92 steps/s\n",
      "episode: 2980/10000, score: 15.0, steps: 121, total steps: 475387, e: 0.010, speed: 71.85 steps/s\n",
      "episode: 2990/10000, score: 5.0, steps: 28, total steps: 477824, e: 0.010, speed: 72.13 steps/s\n",
      "episode: 3000/10000, score: 2.0, steps: 24, total steps: 479384, e: 0.010, speed: 71.27 steps/s\n",
      "episode: 3010/10000, score: 14.0, steps: 125, total steps: 480950, e: 0.010, speed: 69.43 steps/s\n",
      "episode: 3020/10000, score: 107.0, steps: 531, total steps: 483633, e: 0.010, speed: 68.69 steps/s\n",
      "episode: 3030/10000, score: 26.0, steps: 201, total steps: 485966, e: 0.010, speed: 70.67 steps/s\n",
      "episode: 3040/10000, score: 13.0, steps: 238, total steps: 488074, e: 0.010, speed: 68.61 steps/s\n",
      "episode: 3050/10000, score: 34.0, steps: 250, total steps: 490861, e: 0.010, speed: 68.85 steps/s\n",
      "episode: 3060/10000, score: 4.0, steps: 51, total steps: 492249, e: 0.010, speed: 69.52 steps/s\n",
      "episode: 3070/10000, score: 38.0, steps: 206, total steps: 494108, e: 0.010, speed: 68.45 steps/s\n",
      "episode: 3080/10000, score: 9.0, steps: 69, total steps: 495978, e: 0.010, speed: 70.57 steps/s\n",
      "episode: 3090/10000, score: 7.0, steps: 62, total steps: 497867, e: 0.010, speed: 73.64 steps/s\n",
      "episode: 3100/10000, score: 7.0, steps: 126, total steps: 499434, e: 0.010, speed: 66.94 steps/s\n",
      "episode: 3110/10000, score: 16.0, steps: 71, total steps: 501584, e: 0.010, speed: 71.20 steps/s\n",
      "episode: 3120/10000, score: 2.0, steps: 33, total steps: 503339, e: 0.010, speed: 72.46 steps/s\n",
      "episode: 3130/10000, score: 11.0, steps: 215, total steps: 505501, e: 0.010, speed: 69.92 steps/s\n",
      "episode: 3140/10000, score: 24.0, steps: 259, total steps: 508364, e: 0.010, speed: 70.40 steps/s\n",
      "episode: 3150/10000, score: 27.0, steps: 172, total steps: 510195, e: 0.010, speed: 70.01 steps/s\n",
      "episode: 3160/10000, score: 21.0, steps: 249, total steps: 513141, e: 0.010, speed: 71.05 steps/s\n",
      "episode: 3170/10000, score: 3.0, steps: 17, total steps: 514066, e: 0.010, speed: 72.22 steps/s\n",
      "episode: 3180/10000, score: 12.0, steps: 90, total steps: 515481, e: 0.010, speed: 67.98 steps/s\n",
      "episode: 3190/10000, score: 18.0, steps: 148, total steps: 516871, e: 0.010, speed: 69.75 steps/s\n",
      "episode: 3200/10000, score: 86.0, steps: 528, total steps: 518974, e: 0.010, speed: 71.47 steps/s\n",
      "episode: 3210/10000, score: 13.0, steps: 91, total steps: 521082, e: 0.010, speed: 71.20 steps/s\n",
      "episode: 3220/10000, score: 32.0, steps: 568, total steps: 523222, e: 0.010, speed: 70.08 steps/s\n",
      "episode: 3230/10000, score: 33.0, steps: 191, total steps: 524865, e: 0.010, speed: 68.95 steps/s\n",
      "episode: 3240/10000, score: 41.0, steps: 177, total steps: 526721, e: 0.010, speed: 67.53 steps/s\n",
      "episode: 3250/10000, score: 68.0, steps: 561, total steps: 528881, e: 0.010, speed: 69.79 steps/s\n",
      "episode: 3260/10000, score: 2.0, steps: 128, total steps: 530051, e: 0.010, speed: 69.06 steps/s\n",
      "episode: 3270/10000, score: 10.0, steps: 54, total steps: 531708, e: 0.010, speed: 70.01 steps/s\n",
      "episode: 3280/10000, score: 79.0, steps: 544, total steps: 558823, e: 0.010, speed: 70.69 steps/s\n",
      "episode: 3290/10000, score: 44.0, steps: 440, total steps: 560920, e: 0.010, speed: 69.79 steps/s\n",
      "episode: 3300/10000, score: 25.0, steps: 306, total steps: 563199, e: 0.010, speed: 70.70 steps/s\n",
      "episode: 3310/10000, score: 17.0, steps: 118, total steps: 565529, e: 0.010, speed: 69.27 steps/s\n",
      "episode: 3320/10000, score: 12.0, steps: 209, total steps: 568383, e: 0.010, speed: 68.95 steps/s\n",
      "episode: 3330/10000, score: 37.0, steps: 332, total steps: 569607, e: 0.010, speed: 69.58 steps/s\n",
      "episode: 3340/10000, score: 25.0, steps: 259, total steps: 571312, e: 0.010, speed: 72.91 steps/s\n",
      "episode: 3350/10000, score: 137.0, steps: 1599, total steps: 575077, e: 0.010, speed: 70.68 steps/s\n",
      "episode: 3360/10000, score: 24.0, steps: 110, total steps: 576831, e: 0.010, speed: 70.42 steps/s\n",
      "episode: 3370/10000, score: 40.0, steps: 323, total steps: 580539, e: 0.010, speed: 72.81 steps/s\n",
      "episode: 3380/10000, score: 54.0, steps: 378, total steps: 584723, e: 0.010, speed: 71.13 steps/s\n",
      "episode: 3390/10000, score: 4.0, steps: 58, total steps: 586597, e: 0.010, speed: 72.09 steps/s\n",
      "episode: 3400/10000, score: 20.0, steps: 297, total steps: 588384, e: 0.010, speed: 68.95 steps/s\n",
      "episode: 3410/10000, score: 37.0, steps: 199, total steps: 589681, e: 0.010, speed: 69.43 steps/s\n",
      "episode: 3420/10000, score: 72.0, steps: 580, total steps: 592343, e: 0.010, speed: 68.92 steps/s\n",
      "episode: 3430/10000, score: 46.0, steps: 312, total steps: 594379, e: 0.010, speed: 67.63 steps/s\n",
      "episode: 3440/10000, score: 7.0, steps: 150, total steps: 596337, e: 0.010, speed: 71.68 steps/s\n",
      "episode: 3450/10000, score: 67.0, steps: 593, total steps: 599729, e: 0.010, speed: 71.67 steps/s\n",
      "episode: 3460/10000, score: 42.0, steps: 338, total steps: 602251, e: 0.010, speed: 70.48 steps/s\n",
      "episode: 3470/10000, score: 51.0, steps: 377, total steps: 604362, e: 0.010, speed: 71.39 steps/s\n",
      "episode: 3480/10000, score: 21.0, steps: 125, total steps: 606175, e: 0.010, speed: 70.89 steps/s\n",
      "episode: 3490/10000, score: 0.0, steps: 35, total steps: 608104, e: 0.010, speed: 72.16 steps/s\n",
      "episode: 3500/10000, score: 6.0, steps: 118, total steps: 610763, e: 0.010, speed: 70.30 steps/s\n",
      "episode: 3510/10000, score: 5.0, steps: 42, total steps: 613146, e: 0.010, speed: 72.61 steps/s\n",
      "episode: 3520/10000, score: 11.0, steps: 149, total steps: 614132, e: 0.010, speed: 70.88 steps/s\n",
      "episode: 3530/10000, score: 26.0, steps: 146, total steps: 615904, e: 0.010, speed: 71.91 steps/s\n",
      "episode: 3540/10000, score: 60.0, steps: 363, total steps: 642263, e: 0.010, speed: 69.16 steps/s\n",
      "episode: 3550/10000, score: 27.0, steps: 246, total steps: 643808, e: 0.010, speed: 68.19 steps/s\n",
      "episode: 3560/10000, score: 24.0, steps: 201, total steps: 645418, e: 0.010, speed: 68.50 steps/s\n",
      "episode: 3570/10000, score: 16.0, steps: 151, total steps: 647144, e: 0.010, speed: 68.72 steps/s\n",
      "episode: 3580/10000, score: 18.0, steps: 206, total steps: 649068, e: 0.010, speed: 70.11 steps/s\n",
      "episode: 3590/10000, score: 25.0, steps: 258, total steps: 651166, e: 0.010, speed: 68.85 steps/s\n",
      "episode: 3600/10000, score: 59.0, steps: 810, total steps: 653094, e: 0.010, speed: 71.32 steps/s\n",
      "episode: 3610/10000, score: 40.0, steps: 242, total steps: 654609, e: 0.010, speed: 68.85 steps/s\n",
      "episode: 3620/10000, score: 6.0, steps: 50, total steps: 655819, e: 0.010, speed: 68.52 steps/s\n",
      "episode: 3630/10000, score: 0.0, steps: 238, total steps: 657921, e: 0.010, speed: 64.82 steps/s\n",
      "episode: 3640/10000, score: 15.0, steps: 224, total steps: 659598, e: 0.010, speed: 60.02 steps/s\n",
      "episode: 3650/10000, score: 65.0, steps: 412, total steps: 661269, e: 0.010, speed: 59.71 steps/s\n",
      "episode: 3660/10000, score: 16.0, steps: 120, total steps: 663999, e: 0.010, speed: 62.87 steps/s\n",
      "episode: 3670/10000, score: 9.0, steps: 239, total steps: 665655, e: 0.010, speed: 63.44 steps/s\n",
      "episode: 3680/10000, score: 2.0, steps: 96, total steps: 666961, e: 0.010, speed: 58.43 steps/s\n",
      "episode: 3690/10000, score: 15.0, steps: 183, total steps: 668438, e: 0.010, speed: 65.91 steps/s\n",
      "episode: 3700/10000, score: 45.0, steps: 572, total steps: 671208, e: 0.010, speed: 64.51 steps/s\n",
      "episode: 3710/10000, score: 4.0, steps: 55, total steps: 672236, e: 0.010, speed: 66.52 steps/s\n",
      "episode: 3720/10000, score: 60.0, steps: 366, total steps: 673769, e: 0.010, speed: 63.84 steps/s\n",
      "episode: 3730/10000, score: 7.0, steps: 34, total steps: 675287, e: 0.010, speed: 65.47 steps/s\n",
      "episode: 3740/10000, score: 13.0, steps: 136, total steps: 676769, e: 0.010, speed: 60.99 steps/s\n",
      "episode: 3750/10000, score: 0.0, steps: 103, total steps: 678619, e: 0.010, speed: 66.24 steps/s\n",
      "episode: 3760/10000, score: 4.0, steps: 90, total steps: 680317, e: 0.010, speed: 62.49 steps/s\n",
      "episode: 3770/10000, score: 8.0, steps: 154, total steps: 682686, e: 0.010, speed: 62.44 steps/s\n",
      "episode: 3780/10000, score: 5.0, steps: 144, total steps: 684226, e: 0.010, speed: 62.11 steps/s\n",
      "episode: 3790/10000, score: 15.0, steps: 105, total steps: 685768, e: 0.010, speed: 65.95 steps/s\n",
      "episode: 3800/10000, score: 21.0, steps: 212, total steps: 687628, e: 0.010, speed: 65.36 steps/s\n",
      "episode: 3810/10000, score: 0.0, steps: 186, total steps: 689305, e: 0.010, speed: 64.01 steps/s\n",
      "episode: 3820/10000, score: 38.0, steps: 220, total steps: 691532, e: 0.010, speed: 64.59 steps/s\n",
      "episode: 3830/10000, score: 26.0, steps: 166, total steps: 692952, e: 0.010, speed: 60.70 steps/s\n",
      "episode: 3840/10000, score: 0.0, steps: 68, total steps: 694501, e: 0.010, speed: 64.63 steps/s\n",
      "episode: 3850/10000, score: 3.0, steps: 19, total steps: 696520, e: 0.010, speed: 71.87 steps/s\n",
      "episode: 3860/10000, score: 1.0, steps: 37, total steps: 697574, e: 0.010, speed: 67.65 steps/s\n",
      "episode: 3870/10000, score: 4.0, steps: 59, total steps: 699132, e: 0.010, speed: 67.01 steps/s\n",
      "episode: 3880/10000, score: 3.0, steps: 34, total steps: 701725, e: 0.010, speed: 61.47 steps/s\n",
      "episode: 3890/10000, score: 29.0, steps: 246, total steps: 703172, e: 0.010, speed: 64.26 steps/s\n",
      "episode: 3900/10000, score: 14.0, steps: 103, total steps: 704693, e: 0.010, speed: 63.63 steps/s\n",
      "episode: 3910/10000, score: 13.0, steps: 150, total steps: 706341, e: 0.010, speed: 63.03 steps/s\n",
      "episode: 3920/10000, score: 12.0, steps: 95, total steps: 707210, e: 0.010, speed: 65.03 steps/s\n",
      "episode: 3930/10000, score: 21.0, steps: 135, total steps: 709546, e: 0.010, speed: 63.25 steps/s\n",
      "episode: 3940/10000, score: 2.0, steps: 16, total steps: 710475, e: 0.010, speed: 62.99 steps/s\n",
      "episode: 3950/10000, score: 19.0, steps: 134, total steps: 712227, e: 0.010, speed: 60.91 steps/s\n",
      "episode: 3960/10000, score: 11.0, steps: 127, total steps: 713889, e: 0.010, speed: 64.29 steps/s\n",
      "episode: 3970/10000, score: 5.0, steps: 38, total steps: 715201, e: 0.010, speed: 64.59 steps/s\n",
      "episode: 3980/10000, score: 10.0, steps: 122, total steps: 716749, e: 0.010, speed: 64.89 steps/s\n",
      "episode: 3990/10000, score: 2.0, steps: 131, total steps: 718671, e: 0.010, speed: 64.91 steps/s\n",
      "episode: 4000/10000, score: 4.0, steps: 21, total steps: 719863, e: 0.010, speed: 67.10 steps/s\n",
      "episode: 4010/10000, score: 76.0, steps: 416, total steps: 721976, e: 0.010, speed: 64.99 steps/s\n",
      "episode: 4020/10000, score: 3.0, steps: 112, total steps: 723567, e: 0.010, speed: 62.67 steps/s\n",
      "episode: 4030/10000, score: 0.0, steps: 43, total steps: 725350, e: 0.010, speed: 64.91 steps/s\n",
      "episode: 4040/10000, score: 26.0, steps: 175, total steps: 726912, e: 0.010, speed: 65.77 steps/s\n",
      "episode: 4050/10000, score: 53.0, steps: 616, total steps: 729401, e: 0.010, speed: 65.33 steps/s\n",
      "episode: 4060/10000, score: 12.0, steps: 122, total steps: 730778, e: 0.010, speed: 62.38 steps/s\n",
      "episode: 4070/10000, score: 17.0, steps: 137, total steps: 733599, e: 0.010, speed: 67.28 steps/s\n",
      "episode: 4080/10000, score: 4.0, steps: 45, total steps: 734784, e: 0.010, speed: 68.40 steps/s\n",
      "episode: 4090/10000, score: 21.0, steps: 346, total steps: 736139, e: 0.010, speed: 66.42 steps/s\n",
      "episode: 4100/10000, score: 27.0, steps: 322, total steps: 737939, e: 0.010, speed: 66.29 steps/s\n",
      "episode: 4110/10000, score: 0.0, steps: 150, total steps: 739870, e: 0.010, speed: 62.71 steps/s\n",
      "episode: 4120/10000, score: 71.0, steps: 355, total steps: 741503, e: 0.010, speed: 66.08 steps/s\n",
      "episode: 4130/10000, score: 50.0, steps: 333, total steps: 742976, e: 0.010, speed: 64.67 steps/s\n",
      "episode: 4140/10000, score: 78.0, steps: 479, total steps: 744798, e: 0.010, speed: 64.21 steps/s\n",
      "episode: 4150/10000, score: 2.0, steps: 261, total steps: 746459, e: 0.010, speed: 66.85 steps/s\n",
      "episode: 4160/10000, score: 33.0, steps: 187, total steps: 747962, e: 0.010, speed: 61.24 steps/s\n",
      "episode: 4170/10000, score: 54.0, steps: 272, total steps: 749543, e: 0.010, speed: 64.66 steps/s\n",
      "episode: 4180/10000, score: 12.0, steps: 101, total steps: 750744, e: 0.010, speed: 66.53 steps/s\n",
      "episode: 4190/10000, score: 54.0, steps: 324, total steps: 752760, e: 0.010, speed: 66.61 steps/s\n",
      "episode: 4200/10000, score: 5.0, steps: 61, total steps: 753833, e: 0.010, speed: 64.71 steps/s\n",
      "episode: 4210/10000, score: 6.0, steps: 101, total steps: 755218, e: 0.010, speed: 66.65 steps/s\n",
      "episode: 4220/10000, score: 30.0, steps: 237, total steps: 757031, e: 0.010, speed: 64.46 steps/s\n",
      "episode: 4230/10000, score: 8.0, steps: 60, total steps: 759077, e: 0.010, speed: 61.28 steps/s\n",
      "episode: 4240/10000, score: 26.0, steps: 200, total steps: 760580, e: 0.010, speed: 63.39 steps/s\n",
      "episode: 4250/10000, score: 26.0, steps: 328, total steps: 761892, e: 0.010, speed: 63.95 steps/s\n",
      "episode: 4260/10000, score: 10.0, steps: 75, total steps: 763301, e: 0.010, speed: 71.01 steps/s\n",
      "episode: 4270/10000, score: 33.0, steps: 183, total steps: 766065, e: 0.010, speed: 69.66 steps/s\n",
      "episode: 4280/10000, score: 35.0, steps: 198, total steps: 768298, e: 0.010, speed: 68.61 steps/s\n",
      "episode: 4290/10000, score: 59.0, steps: 471, total steps: 770000, e: 0.010, speed: 70.39 steps/s\n",
      "episode: 4300/10000, score: 27.0, steps: 237, total steps: 772239, e: 0.010, speed: 67.90 steps/s\n",
      "episode: 4310/10000, score: 12.0, steps: 134, total steps: 774558, e: 0.010, speed: 70.67 steps/s\n",
      "episode: 4320/10000, score: 10.0, steps: 92, total steps: 776295, e: 0.010, speed: 72.23 steps/s\n",
      "episode: 4330/10000, score: 1.0, steps: 234, total steps: 779152, e: 0.010, speed: 60.94 steps/s\n",
      "episode: 4340/10000, score: 26.0, steps: 151, total steps: 781133, e: 0.010, speed: 64.40 steps/s\n",
      "episode: 4350/10000, score: 6.0, steps: 24, total steps: 782553, e: 0.010, speed: 60.55 steps/s\n",
      "episode: 4360/10000, score: 15.0, steps: 64, total steps: 783953, e: 0.010, speed: 59.43 steps/s\n",
      "episode: 4370/10000, score: 32.0, steps: 285, total steps: 785394, e: 0.010, speed: 63.91 steps/s\n",
      "episode: 4380/10000, score: 2.0, steps: 51, total steps: 787026, e: 0.010, speed: 64.78 steps/s\n",
      "episode: 4390/10000, score: 16.0, steps: 131, total steps: 788362, e: 0.010, speed: 63.95 steps/s\n",
      "episode: 4400/10000, score: 0.0, steps: 51, total steps: 790767, e: 0.010, speed: 57.74 steps/s\n",
      "episode: 4410/10000, score: 25.0, steps: 142, total steps: 792466, e: 0.010, speed: 65.90 steps/s\n",
      "episode: 4420/10000, score: 34.0, steps: 289, total steps: 819933, e: 0.010, speed: 63.96 steps/s\n",
      "episode: 4430/10000, score: 3.0, steps: 28, total steps: 822187, e: 0.010, speed: 61.28 steps/s\n",
      "episode: 4440/10000, score: 29.0, steps: 200, total steps: 823672, e: 0.010, speed: 63.30 steps/s\n",
      "episode: 4450/10000, score: 75.0, steps: 531, total steps: 826199, e: 0.010, speed: 65.35 steps/s\n",
      "episode: 4460/10000, score: 14.0, steps: 202, total steps: 829476, e: 0.010, speed: 65.57 steps/s\n",
      "episode: 4470/10000, score: 10.0, steps: 56, total steps: 831236, e: 0.010, speed: 65.12 steps/s\n",
      "episode: 4480/10000, score: 12.0, steps: 74, total steps: 833137, e: 0.010, speed: 61.59 steps/s\n",
      "episode: 4490/10000, score: 0.0, steps: 19, total steps: 838201, e: 0.010, speed: 64.88 steps/s\n",
      "episode: 4500/10000, score: 14.0, steps: 131, total steps: 840038, e: 0.010, speed: 64.12 steps/s\n",
      "episode: 4510/10000, score: 13.0, steps: 72, total steps: 842173, e: 0.010, speed: 64.43 steps/s\n",
      "episode: 4520/10000, score: 0.0, steps: 62, total steps: 843377, e: 0.010, speed: 65.18 steps/s\n",
      "episode: 4530/10000, score: 111.0, steps: 1354, total steps: 846947, e: 0.010, speed: 64.72 steps/s\n",
      "episode: 4540/10000, score: 20.0, steps: 193, total steps: 848977, e: 0.010, speed: 64.28 steps/s\n",
      "episode: 4550/10000, score: 41.0, steps: 390, total steps: 851335, e: 0.010, speed: 65.72 steps/s\n",
      "episode: 4560/10000, score: 16.0, steps: 209, total steps: 852963, e: 0.010, speed: 63.89 steps/s\n",
      "episode: 4570/10000, score: 134.0, steps: 1149, total steps: 855149, e: 0.010, speed: 64.73 steps/s\n",
      "episode: 4580/10000, score: 7.0, steps: 69, total steps: 857785, e: 0.010, speed: 62.13 steps/s\n",
      "episode: 4590/10000, score: 2.0, steps: 54, total steps: 858773, e: 0.010, speed: 63.98 steps/s\n",
      "episode: 4600/10000, score: 98.0, steps: 540, total steps: 862092, e: 0.010, speed: 64.05 steps/s\n",
      "episode: 4610/10000, score: 9.0, steps: 306, total steps: 864189, e: 0.010, speed: 65.60 steps/s\n",
      "episode: 4620/10000, score: 29.0, steps: 249, total steps: 866325, e: 0.010, speed: 63.25 steps/s\n",
      "episode: 4630/10000, score: 16.0, steps: 207, total steps: 867609, e: 0.010, speed: 63.66 steps/s\n",
      "episode: 4640/10000, score: 25.0, steps: 118, total steps: 869569, e: 0.010, speed: 64.72 steps/s\n",
      "episode: 4650/10000, score: 11.0, steps: 70, total steps: 896114, e: 0.010, speed: 65.88 steps/s\n",
      "episode: 4660/10000, score: 15.0, steps: 125, total steps: 899675, e: 0.010, speed: 65.83 steps/s\n",
      "episode: 4670/10000, score: 9.0, steps: 64, total steps: 901104, e: 0.010, speed: 61.47 steps/s\n",
      "episode: 4680/10000, score: 7.0, steps: 58, total steps: 902539, e: 0.010, speed: 60.05 steps/s\n",
      "episode: 4690/10000, score: 0.0, steps: 71, total steps: 903709, e: 0.010, speed: 63.02 steps/s\n",
      "episode: 4700/10000, score: 16.0, steps: 86, total steps: 906343, e: 0.010, speed: 66.76 steps/s\n",
      "episode: 4710/10000, score: 25.0, steps: 141, total steps: 907936, e: 0.010, speed: 71.29 steps/s\n",
      "episode: 4720/10000, score: 51.0, steps: 253, total steps: 910498, e: 0.010, speed: 72.79 steps/s\n",
      "episode: 4730/10000, score: 33.0, steps: 235, total steps: 912516, e: 0.010, speed: 74.08 steps/s\n",
      "episode: 4740/10000, score: 41.0, steps: 367, total steps: 915191, e: 0.010, speed: 72.51 steps/s\n",
      "episode: 4750/10000, score: 2.0, steps: 43, total steps: 916789, e: 0.010, speed: 71.51 steps/s\n",
      "episode: 4760/10000, score: 10.0, steps: 308, total steps: 918839, e: 0.010, speed: 72.62 steps/s\n",
      "episode: 4770/10000, score: 13.0, steps: 94, total steps: 920790, e: 0.010, speed: 69.70 steps/s\n",
      "episode: 4780/10000, score: 10.0, steps: 67, total steps: 922421, e: 0.010, speed: 72.78 steps/s\n",
      "episode: 4790/10000, score: 52.0, steps: 366, total steps: 924677, e: 0.010, speed: 71.66 steps/s\n",
      "episode: 4800/10000, score: 27.0, steps: 186, total steps: 925962, e: 0.010, speed: 73.36 steps/s\n",
      "episode: 4810/10000, score: 17.0, steps: 103, total steps: 927752, e: 0.010, speed: 73.25 steps/s\n",
      "episode: 4820/10000, score: 0.0, steps: 408, total steps: 929840, e: 0.010, speed: 70.34 steps/s\n",
      "episode: 4830/10000, score: 26.0, steps: 102, total steps: 932547, e: 0.010, speed: 75.45 steps/s\n",
      "episode: 4840/10000, score: 14.0, steps: 82, total steps: 935032, e: 0.010, speed: 73.44 steps/s\n",
      "episode: 4850/10000, score: 21.0, steps: 185, total steps: 936002, e: 0.010, speed: 72.04 steps/s\n",
      "episode: 4860/10000, score: 66.0, steps: 386, total steps: 937073, e: 0.010, speed: 71.49 steps/s\n",
      "episode: 4870/10000, score: 15.0, steps: 219, total steps: 938879, e: 0.010, speed: 72.03 steps/s\n",
      "episode: 4880/10000, score: 13.0, steps: 171, total steps: 940301, e: 0.010, speed: 73.43 steps/s\n",
      "episode: 4890/10000, score: 35.0, steps: 190, total steps: 942355, e: 0.010, speed: 73.44 steps/s\n",
      "episode: 4900/10000, score: 45.0, steps: 264, total steps: 944173, e: 0.010, speed: 73.22 steps/s\n",
      "episode: 4910/10000, score: 1.0, steps: 191, total steps: 946422, e: 0.010, speed: 72.45 steps/s\n",
      "episode: 4920/10000, score: 17.0, steps: 187, total steps: 948406, e: 0.010, speed: 73.30 steps/s\n",
      "episode: 4930/10000, score: 7.0, steps: 30, total steps: 949632, e: 0.010, speed: 75.70 steps/s\n",
      "episode: 4940/10000, score: 9.0, steps: 80, total steps: 951258, e: 0.010, speed: 70.65 steps/s\n",
      "episode: 4950/10000, score: 33.0, steps: 292, total steps: 953206, e: 0.010, speed: 73.87 steps/s\n",
      "episode: 4960/10000, score: 0.0, steps: 124, total steps: 955240, e: 0.010, speed: 71.60 steps/s\n",
      "episode: 4970/10000, score: 14.0, steps: 339, total steps: 957289, e: 0.010, speed: 72.68 steps/s\n",
      "episode: 4980/10000, score: 13.0, steps: 90, total steps: 957961, e: 0.010, speed: 73.37 steps/s\n",
      "episode: 4990/10000, score: 18.0, steps: 106, total steps: 960324, e: 0.010, speed: 73.85 steps/s\n",
      "episode: 5000/10000, score: 72.0, steps: 499, total steps: 962442, e: 0.010, speed: 73.67 steps/s\n",
      "episode: 5010/10000, score: 19.0, steps: 357, total steps: 964248, e: 0.010, speed: 71.90 steps/s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAD4CAYAAADl90xWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABAKElEQVR4nO3dd3wUZf4H8M83CRCQGgkhBDCRloQOOfRUVFBPbNg98M52KqeA58nP86xYwDvPO/Rs6NFEBCkKiAIikSpFIKElhAAJBEggjVTSk31+f2SCS7J9Z2s+79crr+w+OzvzzO7szHeeKkopEBEREfmjAE9ngIiIiMhVGOgQERGR32KgQ0RERH6LgQ4RERH5LQY6RERE5LeCPJ0BAOjcubOKjIz0dDaIiHxKYmJivlIq1Ml1dAkKCpoDYAB480u+xwAguba29onhw4fnmlrAKwKdyMhIJCQkeDobREQ+RUROOruOoKCgOV27do0JDQ0tDAgI4Hgj5FMMBoPk5eXFZmdnzwEw1tQyjN6JiJq3AaGhoSUMcsgXBQQEqNDQ0GLUl0iaXsaN+SEiIu8TwCCHfJl2/JqNZxjoEBERkd9ioENERER+i4EOERH5hZqaGk9ngbwQAx0iIvKYkpKSgOuvv753v379Yvv06dN/9uzZnbZs2dJm6NCh0f369YsdOHBgTGFhYUB5ebncd999kX379o2NiYmJ/f7779sBwIcffnjp6NGje1955ZV9r7rqqn4lJSUB999/f+TAgQNjYmJiYhcuXNgRABISEoIHDhwYEx0dHdu3b9/YpKSkVh7dcXIbr+heTkREnve3bw70OJpd2kbPdfbt2q783/cNPm3u9RUrVrTv2rVrzebNm9MA4Ny5c4GDBw+OXbRoUfp1111XXlBQENC2bVvD9OnTw0QER48eTdm3b1/wrbfe2ic9PT0ZAA4dOtTm4MGDh8LCwuomT54cMWrUqJKvv/46Iz8/PzAuLi5m7NixJR999FHoxIkTc55++umCyspKqa2t1XM3yYuxRIfIz/14KBu5pZWezgaRScOGDav4+eef2z/99NMR69ata5uent6yS5cuNdddd105AISEhBhatGiBHTt2tH3ooYfOAcDQoUMru3XrVp2UlBQMACNHjiwJCwurA4DNmze3f//998Ojo6Njr7nmmn5VVVWSlpbW8re//W3ZjBkzwl955ZWux44da9m2bVv2NGsmWKJD5Mcqa+rw5y8T0TesLdY/d52ns0NezlLJi6sMGjSoau/evSnLly/v8Nprr0Vce+21Jfauo02bNoaGx0opfPPNN2mDBw+uMl5m2LBhlSNHjixbuXJlh9tvv73PRx99dHLs2LGleuwDeTerJToi0kNENolIiogcEpFntfQQEYkXkWPa/05auojIhyKSJiIHRWSYq3eCiEwzqPqb1tMFFR7OCZFpGRkZLdq1a2eYOHFiwZQpU7ITEhIuyc3NbbFly5Y2AFBYWBhQU1ODq6+++vzChQtDAODgwYOtzp4923LQoEFNiipHjRpVMmPGjDCDoT722b59e2sASElJaRkTE1P16quv5t58881F+/fvb+3G3SQPsqVEpxbA/yml9opIOwCJIhIP4FEAG5RS74jIiwBeBPB3ALcA6KP9XQHgU+0/ERHRRRITE1u/9NJL3QMCAhAUFKRmzpx5UimFv/zlLz0rKysDgoODDVu3bj36wgsv5D788MOX9e3bNzYwMBD/+9//Mlq3bt2k+umdd945M2HChJ7R0dGxBoNBevToUbVp06a0hQsXhixbtuzSoKAgFRoaWjNt2rSznthfcj9Ryr5qShFZBeBj7e96pdRZEQkHsFkp1U9E/qc9Xqwtf6RhOXPrjIuLU5zrikh/5dW1iJ36I1q3CMThaWM8nR3SmYgkKqXinFnHgQMHMgYPHpyvV56IPOHAgQOdBw8eHGnqNbsaI4tIJIChAHYBCDMKXrIBhGmPIwAY1/NmammN1zVBRBJEJCEvL8+ebBARERHZxOZAR0TaAlgO4K9KqYsai6n6YiG7ioaUUrOUUnFKqbjQ0FB73kpERERkE5sCHRFpgfogZ5FSaoWWnKNVWUH7n6ulZwHoYfT27loaERERkVvZ0utKAMwFcFgp9Z7RS98BeER7/AiAVUbpD2u9r64EUGypfQ4RERGRq9jS6+pqAA8BSBKR/VraywDeAbBMRB4HcBLAA9prawHcCiANQDmAx/TMMBEREZGtrAY6SqltAMTMyzeYWF4BmORkvoiIiIicxikgiIio2Zo3b16n3r179w8ICBi+devWC/N8ffrppyHR0dGxDX8BAQHDd+zY0WSQwSlTpnTr0qXLoIblli5d2gEAKisrL0xC2q9fv9jVq1e3a3hPZWWljB8//rLIyMgBUVFR/efPn98RAI4dO9byiiuu6BsTExPbt2/fC+tqcOzYsZZt2rQZOnXq1IZeznjzzTe79O7du3+fPn3633HHHVHl5eUCAP/4xz9Ce/bsOUBEhp89e/ZCoUZeXl7gTTfd1Ktv376xAwcOjNmzZ0+w8TZqa2sRExMTO2rUqN4NaQaDAc8880xEZGTkgMsvv7z/9OnTu1haV3l5uQwcODCmX79+sb179+7/3HPPdWtY1/Dhw/s1fFZdunQZdOONN/aylq+IiIiBffv2jY2Ojo4dMGBAjM1froaBDpEfs3OYLKJmZ8iQIRXLly9Pi4uLO2+c/vTTTxekpqampKampixYsOBERERE1VVXXWVyiPGnnnoqp2HZ3//+98UA8P7773cGgKNHj6Zs3Ljx6N///vfudXV1AICXXnopPDQ0tCYjIyM5LS3t0M0333weAKZOnRp+zz33FB4+fDhl8eLFx6dMmdLTeDvPPPNM9+uuu6644fmJEydazJo1K2z//v0px44dO1RXVydz5swJAYDrrrvufHx8/NFu3bpVG6/j1VdfDR80aFD50aNHUxYsWHDiL3/5y0XbmD59eljv3r0v2s+PPvro0szMzBbp6enJx48fP/TYY48VWFpXcHCw2rZt25EjR46kHDp0KGXDhg3tN2zYcAkAJCYmHmn4rIYOHVp21113FdmSry1bthxNTU1NSU5OPmz+2zSNgQ4REXnMkSNHWkZFRfW/9957IyMjIweMHTs26ttvv203bNiw6Msuu2zApk2b2gBASUlJwP333x85cODAmJiYmNiFCxd2bHj/8OHD+8XGxsbExsbGxMfHXwIAq1evbjdixIh+Y8aMuTwqKqr/2LFjoxqmhTA2bNiwysbzYjW2YMGCkLvuuqvQnv1KSUlpPWrUqBIAiIiIqG3fvn1dQ4nR4sWLO0+fPj0bAAIDAxEeHl4LACKCkpKSQAAoLCwM7NKlS03D+r788suOl112WXVMTMxF017U1dVJWVlZQE1NDSoqKgK6d+9eAwBXX311Rb9+/S4KcrTPK/imm24qBeonR83MzGx5+vTpIABIT09v8eOPP3Z48sknLxpAcs6cOV2mTZt2NjAwEA37Y2ldAQEB6NChgwEAqqurpba2VuvX9KuCgoKAnTt3tnvwwQcLreXLWZzUk8iPibnWdUSmfDupB3JT2lhf0A5dYstx1ycWJws9ffp08NKlS48PHz48Y9CgQTGLFi26NCEhIfWrr77q+Pbbb4ePGjUq/eWXXw4fNWpUyddff52Rn58fGBcXFzN27NiSbt261f78889H27Rpo5KSklqNHz/+8oa7/sOHD7fev3//8cjIyJrhw4dHx8fHt20oPbHHqlWrOq1YsSLN3Otz587tsmTJkksHDx5cPnPmzNOhoaF1gwcPLl+9enXHCRMmFKSnp7dMTk5uc/LkyZb5+flVQH2V144dO9pddtllVbNmzTrVo0eP2n/+859nbrrppj5z5szpUlFREbBmzZqjAFBcXBwwY8aMrlu2bDn65ptvdm3YblRUVM2kSZOyo6KiBrVq1cowcuTIknvuucfipKgDBgyo+PrrrzuNGTPm/KZNm9qcPXu2VUZGRssePXrUTpo0qce7776bWVxcHNjo+2n15ZdfdlqzZk2nkJCQ2k8++eTUwIEDqyytq7a2FgMGDIg9depUq0ceeSR39OjRZcbr/OqrrzpdddVVJSEhIQZr+QKAG264oY+I4LHHHst7/vnn7RrJmyU6RETkUREREVUjRoyoCAwMRN++fStGjx5dEhAQgGHDhpVnZma2AoDNmze3f//998Ojo6Njr7nmmn5VVVWSlpbWsrq6Wh588MHIvn37xt5///290tPTL7TtGDhwYFmvXr1qAgMD0b9///L09PSW9uZt48aNl7Ru3drwm9/8pskEogDw3HPP5Z48eTLp8OHDKV27dq2ZOHFiDwB49tln87t161YzcODA2EmTJvUYNmzY+cDAQNTU1EhOTk6Lq6++uiwlJeXwFVdcUfbMM8/0AIDPP/88ZPz48edycnIOrlix4tijjz4aVVdXh7/97W/dJk+enNNQStIgLy8vcM2aNR3T0tKSsrOzD5aXlwfMnDkzxNL+vPXWW2eLi4sDo6OjYz/44IOw6Ojo8sDAQLV48eIOnTt3rh05cmR54/dUV1dLcHCwSk5OPvz444/nPfroo5GW1gUAQUFBSE1NTTl16tTBvXv3XtK4LdCyZctCxo0bV2AtXwCwbdu21JSUlMPr168/Nnv27C4//PBDWxu+ugtYokPUjNz6wc+I6NQasx92anok8ldWSl5cpWXLlhdakwUEBCA4OFgB9dU6dXV1AgBKKXzzzTdpjauZtMbANcuXLz9hMBjQunXr4Q2vtWrV6sJ6AwMDUVtba3cZ56JFi0LuueeeAnOvN5Q4AMDkyZPzbr/99j4A0KJFC8ydO/fC5zl06NDo2NjYyrCwsNrg4GDDww8/XAgAf/zjHwsWLlzYGQAWLlzYed26dUcB4MYbbyyrqqoKyM7ODkpMTLxkzZo1nV5//fXuJSUlgdpnZOjatWttz549q7p161YLAHfddVfRjh072k6cONFsfkNCQgzffPNNBlDfyLhHjx4Do6OjqxYtWhQSHx/fMSIiokNVVVVAWVlZwJ133hm1atWqE2FhYdXjx48vBICHHnqoaPLkyZGW1mW8vc6dO9eNHDmy9Pvvv+/QECyePXs26ODBg5c88MADadbyBdSXXAH1VWa33XZb0c6dOy+55ZZbbC6ZY4kOUTOScrYE8Sk5ns4Gkd1GjRpVMmPGjLCGdjbbt29vDQDFxcWB4eHhNYGBgZg5c+alDQ1+9VBXV4fvv/++08MPP2w2cDh58mSLhsdLlizp2K9fvwoAKC0tDSgpKQkAgJUrV7YPDAxUw4cPrwwICMANN9xQvGbNmnYAsHbt2vZ9+vSpAIBu3bpVr127tj0A7N27N7i6ulrCw8NrExMTj2RlZSVlZWUlPfnkk7nPPvvs2ZdffjkvMjKyeu/evW1LS0sDDAYDNm7c2K5xG57G8vPzAysrKwWobzA9YsSI0pCQEMMnn3ySlZOTczArKytp/vz5x6+88srSVatWnQCAW265pWjdunUN+W132WWXVVla15kzZ4Ly8/MDAeD8+fOyadOm9sb5+vLLLzuNHj26qE2bNspavkpKSgIKCwsDgPp2Wps2bWo/aNAgk43CzWGJDhEReb133nnnzIQJE3pGR0fHGgwG6dGjR9WmTZvS/vrXv+bee++9vZYsWXLp6NGji1u3bt20xbEFCxYs6Pi3v/2tZ2FhYdDdd9/dJyYmpnzbtm3HAOCHH35oFx4eXh0bG3tRo97f//73l02aNCnv2muvLX/22We7p6SktAaA7t27V3/++ecnAeDMmTNBN998c9+AgADVtWvXmq+++upEw/vfe++9zAcffDDq+eefD7z00ktrFyxYkAEA77///uknn3wy8pNPPgkTEXz22WcZAQHmyyNGjx5ddscddxQOGjQoJigoCP379y+fMmVKHgBMnz69y0cffdT13LlzLQYPHhw7atSo4qVLl57cv39/8BNPPBEFAH379q1YtGhRhrXP6K233sq+7777ombOnBnWpk0bw+zZszMAwNy6Tp8+3aKh2k0pJXfeeWfB+PHjL/QW++abb0JeeOGFi2ZMMLeuzMzMoLvvvrs3UN/w+t577z133333WWyH1JgoL+h/GhcXpxISEjydDSK/U15di9ipP6J1i0AcnjYGkS+uAQBkvHObh3NGehCRRKWUU/WQBw4cyBg8eLBdjTuJvM2BAwc6Dx48ONLUa6y6IiIiIr/FQIeIiIj8FgMdIqLmzWAwGDjiEvks7fg12zaLgQ6RH/OCJnjk/ZLz8vI6MNghX2QwGCQvL68DgGRzy7DXFVEzwBGSyZza2tonsrOz52RnZw8Ab37J9xgAJNfW1j5hbgEGOkTNAEt2yJzhw4fnAhjr6XwQuYrV6F1E5olIrogkG6UtFZH92l+GiOzX0iNFpMLotc9cmHcisoIlOUTU3NlSojMfwMcAFjQkKKV+3/BYRGYAKDZaPl0pNUSn/BERERE5zGqgo5TaKiKRpl7T5l1/AMBonfNFRERE5DRnG56NBJCjlDpmlBYlIvtEZIuIjDT3RhGZICIJIpKQl5fnZDaIiIiImnI20BkPYLHR87MAeiqlhgKYAuArEWlv6o1KqVlKqTilVFxoaKiT2SAiIiJqyuFAR0SCANwDYGlDmlKqSil1TnucCCAdQF9nM0lERETkCGdKdG4EkKqUymxIEJFQEQnUHl8OoA+A485lkYiIiMgxtnQvXwxgJ4B+IpIpIo9rL43DxdVWAHAtgINad/NvADyllCrQMb9ERERENrOl19V4M+mPmkhbDmC589kiIj1woEAiau443DdRM8CBA4mouWKgQ0RERH6LgQ5RM8AqLCJqrhjoEPkxb6yyUkrh3z+m4lhOqaezQkTNAAMdInKrovIafLIpHeNm/eLprBBRM8BAh4g8oo71aUTkBgx0iIiIyG8x0CEiIiK/xUCHiMgBO9LyMea/W1FVW+fprBCRBQx0iMgjfL2JzqvfJiM1uxSZhRWezgoRWcBAh8iPeWMw4Y1d3onIfzHQIWoGvCm48Mbgi4j8FwMdIvIIbwq+iMh/MdAhIiIiv8VAh6gZ8MbqIk/m6fVVyYh8cY3nMkBEbmM10BGReSKSKyLJRmlviEiWiOzX/m41eu0lEUkTkSMicrOrMk5E1nlj9ZA35OmLnSc9nQUichNbSnTmAxhjIv19pdQQ7W8tAIhILIBxAPpr75kpIoF6ZZaIiIjIHlYDHaXUVgAFNq7vTgBLlFJVSqkTANIAjHAif0REREQOc6aNzmQROahVbXXS0iIAnDZaJlNLIyIiInI7RwOdTwH0AjAEwFkAM+xdgYhMEJEEEUnIy8tzMBtERERE5jkU6CilcpRSdUopA4DZ+LV6KgtAD6NFu2tpptYxSykVp5SKCw0NdSQbRERERBY5FOiISLjR07sBNPTI+g7AOBFpJSJRAPoA2O1cFonIUd7YrZyIyJ2CrC0gIosBXA+gs4hkAngdwPUiMgSAApAB4M8AoJQ6JCLLAKQAqAUwSSnFqX2JPMwbunT7KwaTRN7NaqCjlBpvInmuheXfBvC2M5kiIiIi0gNHRiYij1B+UhTC0jIi78ZAh4jcSsDIgIjch4EOUTPgJ4UnRER2Y6DjArmlldiYmuPpbBB5ZbWKgn9FXQwiibwbAx0XGPe/X/Cn+QkwGHgGJDJHvDEKIyK/w0DHBY7nlwHwzrtpIm/BxshE5A4MdIiaie1p+Z7OAgA2RiYi92KgQ9RM/GHOLk9ngYjI7RjoEPkxP6kdIiJyGAMdomaA7Uhst+VoHlbtNzkXMRH5IKtTQJDjlOIFhsgcby1semRe/TzEdw6J8HBOiEgPLNFpZPeJAny88ZhT62BwQ0RE5B1YotPIA//bCQCYPLqPh3NC5N/85X6A7aCIvBtLdFyAJz4iIiLvwECHqBlg8O06rKom8m4MdFyI1xYi8/j7ICJ3sBroiMg8EckVkWSjtH+LSKqIHBSRlSLSUUuPFJEKEdmv/X3mwrx7Ld7hEVngB7+PV1YmXZjqhYi8my0lOvMBjGmUFg9ggFJqEICjAF4yei1dKTVE+3tKn2wSEXmPRbtOXXjMakEi72Y10FFKbQVQ0ChtvVKqVnv6C4DuLsgbEfkjBgZE5EZ6tNH5E4AfjJ5Hicg+EdkiIiPNvUlEJohIgogk5OXl6ZANIvIlflCDBYBV1UTezqlAR0ReAVALYJGWdBZAT6XUUABTAHwlIu1NvVcpNUspFaeUigsNDXUmG0RkhjcXnnhz3ojIfzgc6IjIowBuB/AHpeprqZVSVUqpc9rjRADpAPrqkE+fpFh5T17Cq0odvCkvROT3HAp0RGQMgBcAjFVKlRulh4pIoPb4cgB9ABzXI6NEvqzOwKDXX9lyP3P/ZzvQ79UfrC9IRLqzpXv5YgA7AfQTkUwReRzAxwDaAYhv1I38WgAHRWQ/gG8APKWUKjC1XqLmIj3vPHq9vBZrDp61umydQaG61uCGXPkXpRQqa+o8nQ2z9mQUoorfK5FH2NLrarxSKlwp1UIp1V0pNVcp1Vsp1aNxN3Kl1HKlVH8tbZhS6nvX7wKRd0vOKgYArDuUbXXZh+buQl/e+dvt8+0ZiH5tHXJKKt2+ba+qFiSiJjgysp0Ky6pRW8c7M3KNHennPJ0F99GxNu/7g2cAAJmFFfqtlIj8AgMdO1TW1GHotHi8tuqQp7NCPsiTjdPZLt51+NkSeTcGOnaoqqkvyVmj3T2a03Di4/mPAEBYt2EaPxYicgMGOpq03FJWSRE1c2m55+1+D+NYIu8W5OkMeINT58px43tb8eTIKJuWZ0kNOcKbjpvaOgOCAnmfYyy3pBI3vrfF09kgIp3xTAcg73wVACDhZKHlBXnnRn5iRvxRT2dB18hPj3YyRRU1zq+EiLwOAx0A3nWvTf7KE3GyuQbQSZnFbs6J99t9wrEhv9gYmci7MdAxYvOFiCc2coAnDxtvaEeSnFWM7GLXjHPj7P6l5Zbi1W+T9ckMEXkVBjpmnDtfhR1p+U6tg3d6BHhnjafyQNh1+0fbcNU7G9y+XWvKq2uxfG+Ww+/3hiCSiMxjoAPTAcmDs3fhwTm7YDA1R5GZE1udQWHlvkx9M0d+qbi8ButtGCnZ3xgUvK5E9KUVSfh0c7qns0FELsJAx4jxeCdHckq1NBMLmjlRL9iZgeeWHnBBzsgvGB03E79KxIQvEy1OWbAnowCHz5a4IWPmZRVVYMPhHNesXMeSEGdKTzPOlVtfiIh8FgMdO1gros7Xem85Ymf6OTYQ9VOmjpuT2sXV0gSe93+2E7d88LOrsmWT2z78GY9/kYAlu0/pv3ILwcnpgnKsS7Y+CWpjnqhGYhU1kXdrNoGOUgpzt51AaaV9XUjddRIbP/sX3PHxNvdsjNzKly+EReX1v5cXVyThwOkit2335v9uxVML97pte0Tkv5pNoLPlaB6mrU7Bm9+nNHnN1HXI0p2hrdctTzT4JDJFj2CrykLpk97Kq+vsWr4hbzUO5NHZQiA2Ribybs0m0KnU5qkqsTAomPH5ytSFwdr5TLyyfw15Gi+ErtfQlmnhLvur2Hg7QuTfbAp0RGSeiOSKSLJRWoiIxIvIMe1/Jy1dRORDEUkTkYMiMsxVmdeLpbtdZeYxkR5sKWn517pU1Jnq/efi7fqiyhr7SoL04K+fJZG/sLVEZz6AMY3SXgSwQSnVB8AG7TkA3AKgj/Y3AcCnzmfTPYzvvHkXTnpztCrz083p2ObkmE560Ps34S3xgbndeuO7QzjnRAcDIvIONgU6SqmtABqPj34ngC+0x18AuMsofYGq9wuAjiISrkNePY6xDznCUpWmrcGDwcFiA1cEE0opTFudgvQ8+2f6Blzbdk3P3+j8HRkm2/QRkW9xpo1OmFKqof9nNoAw7XEEgNNGy2VqaRcRkQkikiAiCXl5eU5kwzVYHE168YZG6RU6VumcKijH3G0n8Kf5e5xajy/cONTZcCJg6S+Rd9OlMbKqnznQrrO5UmqWUipOKRUXGhqqRzZcwtSkiOYmSmy6nN65IdLXSyuS8POxX280TuSX4YkvEmxq6+KNx7cjWbIUqKw5aP9YPg0W/nISn23hiMtEnuZMoJPTUCWl/c/V0rMA9DBarruW5rUaApc9GYUWlxMrt268syNTvLk33uLdp/DQ3N0Xnk9dlYyfDudgl5mZvF9emXRhXihvKKnSg7MBm7n3v/ptMt75IdW5lROR05wJdL4D8Ij2+BEAq4zSH9Z6X10JoNioisun2VqSQ2QrXzukvtp1Ch9uOKbLulyx6/aGlCv2cm46In9na/fyxQB2AugnIpki8jiAdwDcJCLHANyoPQeAtQCOA0gDMBvARN1zrTNLJ1wfuw6RFzMV1Dw8b5f7MwJ9Ayw92ut4ypRlts1Nl5xVjKv+uQHF5faNrG7JxtQc3PTeFtTUuW8gRqLmKMiWhZRS4828dIOJZRWASc5kyltZq7oiMsXSYeNLE0qa241pq72nZ5Ij8dt+G6a2+HDDMZwprsTO4+cwZkDXi15z9LTw9+VJyCutQmFZNbq0D3ZsJURkVbMZGZm8xxNf7MFzS/d7Ohtex9vHbNGrEMjXquusYTscIu/GQAdWRkY28Zqfnafd7qfDuVi5z6vbp3tE4knLjeH1pEfhpLMBS+MsDJsWj/fWH7ko7eS5Muc2ohNLuxqfkuOydROR8xjo2IEVV+Qqs7amY8KXiW7bniNBit7Hf+MsFJRV48ONaRelbTlq3xhbrv6N6ll7zfMJkXsw0NHJp5vT8VGjkzSROY0vmO+uO2J6QbJoxd5MRL64xtPZICIv1owCHUeH0FdGj837eGPTLrfRr63D6QLHGptGvbQGj8zbbX3BZkgp5fKu/mP+uxVX/XODrus0zrK72qm4cjvu2Adr2/hi50nXZ6IRDjNB5FuaUaBjnisHPjt0psSh9yllf7F9c3Hbh9vQ6+W1Lt1GanYpzhRX6rIub6yicOSY94VOh+b2qrbOgNo6A6pqnZsKY3taPqJecu2xR0T6sql7uX/wgbO0BxkMChU1dbiklXccEuXVtWgVFIjAgKbfW8pZx4JHdyutrEFbGz9PW8OO0soatAtu0SS9sqYOgQGCFoGuu3dpXJDhC4FPg96v/HDh8Yz7Bzu8no2pudYXIiKvwhIdB/hjT6z/rD+C/q//iNJK/QZEc0bs1B99ugv6ifwyDHxjPRbv/nV+W3tKUc4WV1ycoICkzGIMfGM9Vh8802T56NfW4f7PdjqcX0c4P3WCZ341Px7Ktvs9vl4FSNSc+VWgU1RejYpq24um6wwKuSWVFqMUXzgJFZRV2zQJoyWr9tdfPIsrvCPQAYDvDjS9oPuK9NzzAIANh013PW5cGtK4cCSrsFGgAyD5TDEAYNuxfJPrtGXgu1+357niGF1/Uo1+oLaMXOzM9nXtdeVDJWJEvsyvAp0hb8Xjlg+2mnm16entX+tSMeIfG3CurNrpbdtyziqtrHHJoHDDpsXjD3M8M5UAmWbqYmopuLB68dX5ophdYrn90SkT49fofWG2ZaRxe0t9dmfUT0Z6Ir/MbEeAbCfaXukZIPrCTRSRP/COBhk6smdI/Ya77cJy+wIdRxsvX/XORpRW1iLjndscer8leg02x5OvfU7klyGiY2u0DDJ9z2B8LXe20XuBDgF5gxP5lgfie23VIXQPaaPb9lzGRLB0vqoWo/6zGQBM/taSsopdnSsi8iJ+VaJjSmVNHY7llEKPW2JLd5e2XMJKK2udzgN5TllVLdLzzl94fu58FUb9ZzNe/y65ybLGx4qpggtrAaWpl//9o3vH2kk9W6rbutJy9VuXNeVVvvE7Y9UVkXv4faDz1yX7cdP7W1Febf7kZ28phifbN5DnPPFFAm6YseXC8xItcN2Zfs7Cu2w7VrzxiNJz2IWzJqqLGoLB6loDDtjRvsjbJWUWO91mjoj043dVV439cqL+IlRda2jyWkMbAXvbAdhzAeBdm//YedxSQGOdpcOs1nDxi3ocNgdOF6Fzu1Y6rMm1pq1OwZe/ODjwn4kPNf+8flV8Rhuyaamckkrc8fE23DM0wuwy585XIbf017Z6rhzHi4iaQaDjLGsx0LnzVThlYfRjtnlpnqyFLa4OgCtr6nDnJ9vRv1t7125IBwdtbDNzLKcUrYIC0fNSy22Hbv3w5wuPq2rr0Coo0Kn8GTP3va3an4Wxg7tdGJ7hQGaR2XWM+eBn5JVWoWv7YN3yRUTmORzoiEg/AEuNki4HMBVARwBPAmgY1vdlpZTHhxJtuPAcyz1v9jVH3D1zB04VlKNNS/1OpuQ/6i+M7o92G0qIHB2Z27SLr/L2lITqUd170/v1PSovamBsJWJ8e81hvHXnAKe3bc2zS/ajTcsgRHW23oA7r1T/npdEZJ7DbXSUUkeUUkOUUkMADAdQDmCl9vL7Da95Q5BjzFpvE1sYn98tleY4ynKbD/IF7ijJW5t0Fl/tOuX6Dengojnj3FjMqcfv3dhJC706c0v1mTKEiPSlV2PkGwCkK6XcP8OejXypqUyRme7uq/Zn4bzWoyQ5qxj7TunTpZxcrenR58y1XgRIOVOCiYv24uWVSTZu0X6sdrVPUia7rRN5I70CnXEAFhs9nywiB0Vknoh0MvUGEZkgIgkikpCX55nJKxsuBpZO6LbOXm52GzpFWEmZxXh2yX68vKL+wnb7R9tw98wd+qycPMpSj8ALGs18btwOxRc4WnVl9TfnRdHYkj2nrS9kghftApFfcjrQEZGWAMYC+FpL+hRALwBDAJwFMMPU+5RSs5RScUqpuNDQUGezYZWlc4m955maOgPm/HwctXVNe3I1WbdOJ7Ey7WJobURb8hb1X7w0SalnHABPX3PYLTnyVduO5WOvh0sv7f0d27I4e2QSuYceva5uAbBXKZUDAA3/AUBEZgNYrcM2vIpB1V+cWrWw3gD5231Z6BV6CfqEtdNn47z78zillE3TFwD1F7Pj+SYawBt9j6amBWnyNRttbvneTLPb+3ZfFmK7tUdEx9ZW83bcaPBDR3on2Xoo7jtViPgU+yfSbPDHuRamN3FDtLDpSO6FqSX0ZGpsISLSnx5VV+NhVG0lIuFGr90NoOmwsT7E0p2c8YXCnHWHsi/0FnGGq0/nvLt03JniSszamm729XfXNR3RONNo0k57Swtq6sy/4a9L9+N372+16fu87cNtFx7P25ZhXybscPfMHfhip9c237Pqsc/32D2q+fE8fRtBE5HjnAp0ROQSADcBWGGU/K6IJInIQQCjADznzDbcwdFeIJ9vz9A3Ix7EdgKm/fOHw1ZHua2uNeAfa1NNTiK5J8N6lcuRnKbTI7gj7qww2q8KG0bybRw8OXvMNMdDbvFu3+glR+RPnKq6UkqVAbi0UdpDTuVIZ+YuGBtTc0yOqeModwUKHEXVvf635Ti6tAvG49dEWV3WYHQQNDy0ZSLOWgslNL+u0PoinrDQaETj3ScKcCS7BA/9NtKpddYZmn6OZvlYhP7SCtO95IjIdfx+ritz/jQ/wabl3H0aNTcLua1tQhzl71VXtXUGTF2VjGwH2kXY0ugc0Peaa8+qTJVIbkq1syejA5kXAV799tea6Qf+txOvrTpkfVNWXt+Wlm93XrxFVpH9x5dvhWpEvsfvAx09TyKWrgX2BApJmcWYtjrF5AXq3k8tdxn3sRtYr7EtLR8Ldp7ESysOOr0uW74DU4s49d1ZOL5MDVo56au9dq3+i50n8eLygyar38xx9lg0t0sGe1Zs5Yfn7t/L/y3b794NEpFVfh3ovB9/FEXlNVaXc/fJ8I6Pt2HuthOoMjHRqKf5ayDVsFsGL9y/rKKKJmn2FLDp8Z0VV9RgyZ7TyLAw8q+t/vb1ASSedKKXkhd+R7Yy9V0s3cN2OUSe5NeBzgcbjtm03NtrzY9jYmtDZUcuNuNn/4K03KYNUT3BuBeQPykur8EDn+3EGRPBhCdU1tThwdm/6LpOb4sLvk7MxMNzd1tdztvyrYeAgKYh6t+Xs10OkSf5daDj7fadKsLbNg4W5642NL7UVqe61oB7P92BXcfNzw226kAWdmcU4NPN5rt/68X4wm0u8N11ogA7HJnLzAuigsaHhjsaxjs7MrK7j2cTcQ4ReVizDHTMzQ/kCfZeKlx9afGlqqvTheVIPFno9p4s7viIvOFrsFaaWVhmvlrYG/IPuP94DvClOwWiZsJvAp1bPrA894/xCc8VMz47en4rq7I+ENmcn4/j/s92OraBZs5Tlx13DgPgrtnAG2+l2kJvtPLqOgyfFn9hEtrmwpHRjt05mztRc+Q3gc7hsyUuWa8y+6TRclbOVXvMDCF/JNt6Gx3OheQ8Z64lu0/oNfy/7ZloEqB5IGL7z/qjTr3/XFk1Uk38Lu35LqwGAVbuMLal5dvdA42I/IvfBDrebvbW457OAsGxkrcNqbn6Z8ROj32+x+xr7ioPcFespXdp2JqDZ3VdHxH5FgY6PsbSHW7ki2tQUmm9O31zpkctgS1VDf44PcLdMy2P8eQRrPYhIiuaTaDjaBsaV59H9V69PQO+NdBjED2v5UWNQ5WyvVRkgQ9PgmnM2Y8/PiVHn4wQUbPVbAKd5nbjF/niGkxaZFvbhMW7T1947EtzaTnS1sOVcY9NJT02ruv7A2fs2K7Ni/qcXbq1j/Je/vz9EXmD5hPoePgCbukCG/niGt22Y3zSXJNkum1CtY0jMtu6nB4MBoUaG+eU0tPba1IQ+eIau3q+1NgyCacJrguy/OtKadeF34tK7IjIO/lFoFNebb0LqzjalNLLriHOZud0QTn6vvoDliWctrjcj4ey0ffVH1zWm62xvyzZhz6v/GDXexpf4yqq6y6a+dqU8qq6i57P/vmEXdsEgJip66zOSm5urqvmdll2NCi0JP98FSpr6twaiBOR7/L5QOd8VS1ip/5odTk9bvw8XSoE1F/MnXFMm3LiBzOlPQ0B4YbD9W0jDmYWObU9W63WoWdMzNR1eP7rAxelNf7ad2cUICO/zOlt5ZTYP15KczRulvnpLsqr61BZY//xHDf9J0S/tg7Dp8ez3oeIrHI60BGRDBFJEpH9IpKgpYWISLyIHNP+d3I+q6aVVNjWy8jT50OzJUp25ivVyrg7zvf2cWwFlTV1KCq3XMqhN1P7unJflulljR4fzz9v07ossTbDtjsHgfP0sW0v42Ns1H82O7ye0srmNRghETlGrxKdUUqpIUqpOO35iwA2KKX6ANigPXcJ01UETVMdvYCfLiy36aJVYeXOtMyG6jVvYu/Fc9ysXzDkrXjXZMYLORJcuGriVB+Lcy7iyEjCRET2cFXV1Z0AvtAefwHgLhdtx6SvEzN1W9ftH23D3G32t+No7Odj+TrkxnvtP13k9m3q2Q7V3mChsLwa585X2bWOIzmlOF1of/f/5qbcnupZNkYmIiv0CHQUgPUikigiE7S0MKVUQ6OLbABhjd8kIhNEJEFEEvLy8nTIxq/2nSrSdX3mpm/Qg95343q1I/KF64ctpSoN+2FuWUf386G5u3GfA/OP5ZRUWV+omTnQKEh+ZvE+z2SEiPxSkA7ruEYplSUiXQDEi0iq8YtKKSUiTS4zSqlZAGYBQFxcnM7X+6arc7jXFQArHXm8irPtNaq8oCdLclZxk7TMwnIEBQSga4fgpm8Qx9vENLyt/v2uj+5yXFBV42ttdHTVrHeeiGzhdImOUipL+58LYCWAEQByRCQcALT/LpssyNQFLvFkIYobNVJ2ppt0wyZcMXiZtxWcvLjc86MkZxU1bctyzb824cp/bjD9BuV91ztz+VlqpVs/2edAZtOgmIjImFOBjohcIiLtGh4D+B2AZADfAXhEW+wRAKuc2Y69juacxx/n7Loo7ctfHB9Sv7SyBtvT8vHnLxOdzVoT+lddNVVeXYtfjp+z6f37PNDWxlHG1U7WPkd3DA3gbcEWERE5X3UVBmCl1F9xggB8pZRaJyJ7ACwTkccBnATwgJPbsVuSieoPR+06UeCy3iHnq1zfG+v5rw9gbVI2Zv5hGIJb+PzQSRcYBxbmqq4aqiyttY3x5RjFG8Z3IiLyVk4FOkqp4wAGm0g/B+AGZ9Ztex7csRXvqmLalGpfTeDhs/Vj70xctBef/mGYxWWVAnJLK32rdELsC1Scaa9lTVlVLban5bs1+PCp7wrA9wecHxySiMhW/nN772Le1Avpsfl7zL5mqmTDeHC76WsOW13/3Z/scCxjnqLMD+Bn6nszFYToESzkllbiheUHMeHLRKTlNh2U0FVOnnN+pGd3mrY6xdNZIKJmxOcDnW/NjITbXFm7Xptq6GtqmcSThfpkyE28oVTjwdm7cOpc/Tg5ZVXOTdVhj6cW2jZLPRFRc+TTgc6J/DLMiD/qlm15U4mOJaYu+KbSyqvrMH/7CbNtW47rMB+UuxzPL0NR+a+97KzNgm6q6srayNbzbBw0sqG0yFeOF/I8bwjSifyZTwc6VbXuu2t2ZbsOZyzYmWF1GVNVNbtOFOCN71MQn5Ljglw1tSzh9IXSDkt+OX4OO9J+HUW6oroOn21Jt/q+Z5eYHmQu20QjclOfx3NL92PZHvNdv9+ysbql4aLlrccLEVFzo8eAgX4vNry9W7f39CLbqyKmrjpkdRlLd4zWSjLsdbqgHD8dzsFjV0cBqB/ob/2hHLy1OgWd2rTAvqm/s/j+xrNdz1h/BHNsKE3JbzQdg8GgMHNzGj7YcMymfG9MzcXG1FzcO7w7AgMYpJD7sNcckWsx0LFBanYJ5u/I8Mi2V+6zd94u1zS0tdUf5uzCqYJy3D00Ah3btMTDc3dfqAYrLK+xezoNW7vfN97Fn9Py8Z/1pqs1LZW2ODtCMqshiIi8i09XXbmLQXlm0koAeG7pAbuWf2v1YVTYMymiFeaCAqUU/vvTUZxo1JanpLJGe73+eVGjEarvd2B+KJsYBRgCoMpCSdX0NSlW2/E4mw220SFbsZqTyLUY6PiZA6eLMG+787OtNzBXrJ53vgr//ekYRv1ns8PzTOnJuHu5tdyk55VhbZLpsVy2p9s2grQ5DZ/Fwcwip9ZDzQerrohcy6cDHd4JmWZoNAuppUDE4RjF6H2fWmgs7GwQZGvJSOOt/GtdqsnlLixvJluPzNtt2wat2JPhW93ziYj8lU8HOmRa4+DAmVDDbDBplPzuuiNNXlaN/ptTWFaNCQsSHMqbsYtKdFR9qY0lCgp5paanhXj+a/uqC4mIyHsx0PFzGfllTs3T9c66VIvdrq2xVqAzb/sJrNehi7vBqMmNrVUBH2803SPrm0R7G4AbbZu1EEREXoWBjh8SoyKdf/5gfcoHSwrKqvHC8oNNt2FjtaG5qRka2BsYLNplehZ64xGfbVmnqwIStrcgIvIu7F7ezDlyYX708934TWSI1eVq6gworXRudvatR/Mvev7KymSr7/nITEmNOxzNcd8cV0REZB0DHT9XZ9C3RAUANh/Jw+YjeVaXyylxvMqsgaW5ub4/cMZk+iebrI+kPGXZAbRtxcOfPI/VnUSuxaorP2Tc0+mnw7lu3bbxnFO2+HhTmsPbsnXUY3NsHYyQiIh8l08HOhyUzXmFdgYm9hArX1DjwQaJiIj05nCgIyI9RGSTiKSIyCEReVZLf0NEskRkv/Z3q37ZJVvYUxSenFVs87IZ+WWIfHGNTcsOmxaPGeubdjs3tv5Qts3bJvJXW45arwYmIsc5U6JTC+D/lFKxAK4EMElEYrXX3ldKDdH+1jqdS3IZewrF7D0hr9ibZXnbLJEjwhc7MzydBSK/5nBrTKXUWQBntcelInIYQIReGSPHzYg3PZmlKdaql1yJI1sTEZGr6dJGR0QiAQwFsEtLmiwiB0Vknoh0MvOeCSKSICIJeXksuvUUW+Ocga//qPtEmG+vdW6MHyIiImucDnREpC2A5QD+qpQqAfApgF4AhqC+xGeGqfcppWYppeKUUnGhoaGObduhd5ExW9vzlFbVYvoaBiZEumP3ciKXcirQEZEWqA9yFimlVgCAUipHKVWnlDIAmA1ghPPZJFc5X+W6XldEZB3jHCLXcqbXlQCYC+CwUuo9o/Rwo8XuBmB9KFvymB8POT/PFBERkbdyZmjYqwE8BCBJRPZraS8DGC8iQ1B/o5IB4M9ObIOIyK9V1dR5OgtEfs2ZXlfbYLqZDLuTExHZ6Eyx81OlEJF5Pj3ZT4v8FGxv9Yyns0FE5LANdcMA3ObpbBD5LZ8OdAwt2mJ73QBPZ4OIyGFHVA9PZ4HIr/l0oFPdvgdeqGUTICLybW97OgNEfsynJ/U06Dt+HREREfkZnw50WrXw6ewTERGRi/l0pBAUwLGRiYiIyDyfDnSIiIiILPHpQOdMEcefICIiIvN8OtDJO1/l6SwQERGRF/PpQCdQ2EaHiIiIzPPtQIeNkYmIiMgCnw502OuKiIiILPHpQOfKXpd6OgtERETkxXw60GnbyqdnsCAiIiIX8+lAh4iIiMgSlwU6IjJGRI6ISJqIvOiq7RB5mydHRtn9HmvNzTLeuQ3jR1ie5XrphCvt3i45bmBEB09ngYhs4JJAR0QCAXwC4BYAsQDGi0isK7blKjfGhAEAIi9tY3G5rX8b5Y7skA95+dYYu4Mdcz0IX7k1Bl89cQUAYNqdA/DQlZfh5Vujmyw34/7BuOLyS5E6bQzuHNINtwzoinuGRVy0zJSb+tqVJwAYENHe7vc0ByMiQ/D9M9fosq4borvosh4iMs1VJTojAKQppY4rpaoBLAFwp4u2BcD0yeLq3qYbK/8mspPV9d0yoCsAILhFIOY8HGdymW8nXY2eZgKhZ2/oc1Eboj9c0dPqNsn7DO5u/127iOCV236N68M7BJtc7s2x/S88ftVo+eQ3b77w+MlrL8dVvTsDAIICAzDtrgGYcG2vJuvq17UdgPrj9YNxQ/HpH4fj9Tv649GrIhGtvTZmQFf88tINF95z99BfAyFzv4llf/6tyfSMd25Dxju3mXzNEf/nQBDmLp/9cViTtFdui7H4nh+eHYnr+4VaXXdY+1b4+MGm6yci/biqNW8EgNNGzzMBXGG8gIhMADABAHr2dDwI2Pb3UViemIW/3NAbc7edwPa0fJwqKMcDcT0wbkRPfPDTMYgAtw4Mx0+HcxAogik39cU3ezMR1fkSnMgrwwvLD+LV22KQd74KD8T1wLf7snD30AhkFVXg7qER6BHSBp88OAwr9mbiqet74f7PduKuId0uXAQ/Gj8UQQGCOdtOYFjPjgi5pBWevr4X7hgcjnnbM9C9U2tMvL43xo/oicSThSivrsPN/cOwPiUHN8WGYdfxAry8MgkAMOHay9GuVRCeGHk5nlyQgG1p+QDqL0RVtQYczCxG1/bB2PT89YiZug4BAtw9tDv2nS7E8byyC5/LZZe2we2DwnFjTBj+NH8PBkR0QGF5Ndq2CkJuSRU6tmmB6/t1wTOje2PKsgO4pFUgFv5y6sL7H70qEvN3ZAAA+ndrj0NnSnBFVAh2nSgw+T18OH4oNh/JxYq9WU1eGxDRHpmFFSgqr7mQFhPeHofPllj9fieN6oUzRZVYua/pek0ZENEeyVmW1ysCPHFNFLannUOKhTxsfv56BAUKrvnXJgBAr9BLkK59xtFd2yE1u7TJe5667tcg5KsnrkBuaRVuiOmCjzem4cEremLlviwcyS5Ft46tMW5ED5wpqsBfbuiDlkEBeGt1Cpb9+Uq0bRWE1++IxRVR5nsVrpx4FfadKsL+00UI7xCM/t2alrx0aN0Cb4ztj6yiCnydcBp9urSFiGD+Y79BWVUdbhsUjt5d2uLWgeGI6nwJSitrMPCN9QCAru2D8ejVkWjTMggTrr0cs7YeR9f2wRjYvQPG/ebXKrQlE67EH+bsQp1B4fvJ1+COj7cBqA/uzhb/OkXLC2P64YboMNz8360Y95seWLKn/vQwIjIE58qqMG5ETxzMKkb++SrsO1WEfmHtcOXlIUg4WYhDZ379jkZHd8E9wyLwf8sOoKrWgKm3x+Kt1SkAgEd+exnKquvQoXULnDxXjn/fNwgj/vETVk68GjM3p2FtUjZatwjEVb0uxYbUXJPf4bv3DUJVTR2O55ehdYtA9OvaDr+L7YrbBoUjrF0wnrw2Cot3n8Yg7be/4E8jUFBWjb8u3Q8AaBkYgK4dghET3h7zHxuB4ooazNychsmjemPgG+txc/8w/HgoB+2Dg3DPsO54wyjYJSLXEKWU/isVuQ/AGKXUE9rzhwBcoZSabGr5uLg4lZCQoHs+iIj8mYgkKqVMFzkTEQDXVV1lATBuOdldSyMiIiJyG1cFOnsA9BGRKBFpCWAcgO9ctC0iIiIik1zSRkcpVSsikwH8CCAQwDyl1CFXbIuIiIjIHJcNLayUWgtgravWT0RERGQNR0YmIiIiv8VAh4iIiPwWAx0iIiLyWwx0iIiIyG+5ZMBAuzMhkgfgpBOr6AwgX6fs+ILmtr8A97k5aG77Czi/z5cppazPNUHUjHlFoOMsEUloTqODNrf9BbjPzUFz21+gee4zkbux6oqIiIj8FgMdIiIi8lv+EujM8nQG3Ky57S/AfW4Omtv+As1zn4ncyi/a6BARERGZ4i8lOkRERERNMNAhIiIiv+XTgY6IjBGRIyKSJiIvejo/zhCReSKSKyLJRmkhIhIvIse0/520dBGRD7X9Pigiw4ze84i2/DERecQT+2ILEekhIptEJEVEDonIs1q6P+9zsIjsFpED2j6/qaVHicgubd+WikhLLb2V9jxNez3SaF0vaelHRORmD+2STUQkUET2ichq7bm/72+GiCSJyH4RSdDS/Pa4JvJ6Simf/AMQCCAdwOUAWgI4ACDW0/lyYn+uBTAMQLJR2rsAXtQevwjgX9rjWwH8AEAAXAlgl5YeAuC49r+T9riTp/fNzP6GAximPW4H4CiAWD/fZwHQVnvcAsAubV+WARinpX8G4Gnt8UQAn2mPxwFYqj2O1Y73VgCitN9BoKf3z8J+TwHwFYDV2nN/398MAJ0bpfntcc0//nn7ny+X6IwAkKaUOq6UqgawBMCdHs6Tw5RSWwEUNEq+E8AX2uMvANxllL5A1fsFQEcRCQdwM4B4pVSBUqoQQDyAMS7PvAOUUmeVUnu1x6UADgOIgH/vs1JKndeettD+FIDRAL7R0hvvc8Nn8Q2AG0REtPQlSqkqpdQJAGmo/z14HRHpDuA2AHO05wI/3l8L/Pa4JvJ2vhzoRAA4bfQ8U0vzJ2FKqbPa42wAYdpjc/vuk5+JVkUxFPUlHH69z1o1zn4Auai/eKUDKFJK1WqLGOf/wr5prxcDuBS+tc//BfACAIP2/FL49/4C9cHrehFJFJEJWppfH9dE3izI0xkg2yillIj43VgAItIWwHIAf1VKldTfwNfzx31WStUBGCIiHQGsBBDt2Ry5jojcDiBXKZUoItd7ODvudI1SKktEugCIF5FU4xf98bgm8ma+XKKTBaCH0fPuWpo/ydGKsaH9z9XSze27T30mItIC9UHOIqXUCi3Zr/e5gVKqCMAmAL9FfXVFw02Hcf4v7Jv2egcA5+A7+3w1gLEikoH6quXRAD6A/+4vAEAplaX9z0V9MDsCzeS4JvJGvhzo7AHQR+vB0RL1jRe/83Ce9PYdgIbeFo8AWGWU/rDWY+NKAMVasfiPAH4nIp20Xh2/09K8jtb2Yi6Aw0qp94xe8ud9DtVKciAirQHchPq2SZsA3Kct1nifGz6L+wBsVEopLX2c1kspCkAfALvdshN2UEq9pJTqrpSKRP3vc6NS6g/w0/0FABG5RETaNTxG/fGYDD8+rom8nqdbQzvzh/oeC0dR387hFU/nx8l9WQzgLIAa1NfHP4769gkbABwD8BOAEG1ZAfCJtt9JAOKM1vMn1DfWTAPwmKf3y8L+XoP6tgwHAezX/m71830eBGCfts/JAKZq6Zej/sKdBuBrAK209GDteZr2+uVG63pF+yyOALjF0/tmw75fj197Xfnt/mr7dkD7O9RwXvLn45p//PP2P04BQURERH7Ll6uuiIiIiCxioENERER+i4EOERER+S0GOkREROS3GOgQERGR32KgQ0RERH6LgQ4RERH5rf8HAIqYtr634MYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.shape[0]\n",
    "\n",
    "# Hyperparams (should be sufficient)\n",
    "episodes = 10000\n",
    "annealing_steps = 100000  # not episodes!\n",
    "gamma = 0.99\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.000004\n",
    "alpha = 0.0001\n",
    "batch_size = 64\n",
    "memory_size = 200000\n",
    "start_replay_step = 100000\n",
    "target_model_update_interval = 1000\n",
    "train_freq = 4\n",
    "\n",
    "agent = DQNAgent(action_size=action_size, state_size=state_size, gamma=gamma, \n",
    "                 epsilon=epsilon, epsilon_decay=epsilon_decay, epsilon_min=epsilon_min, \n",
    "                 alpha=alpha, batch_size=batch_size, memory_size=memory_size,\n",
    "                 start_replay_step=start_replay_step, \n",
    "                 target_model_update_interval=target_model_update_interval, train_freq=train_freq)\n",
    "\n",
    "statistics = interact_with_environment(env, agent, n_episodes=episodes, verbose=True)\n",
    "env.close()\n",
    "plot_statistics(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T23:22:55.179086Z",
     "iopub.status.busy": "2023-01-06T23:22:55.178786Z",
     "iopub.status.idle": "2023-01-06T23:23:13.894906Z",
     "shell.execute_reply": "2023-01-06T23:23:13.893664Z",
     "shell.execute_reply.started": "2023-01-06T23:22:55.179060Z"
    },
    "id": "kxXdW7Biea4M"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    state = env.reset()\n",
    "    img = plt.imshow(env.render(mode='rgb_array'))\n",
    "    for j in range(200):\n",
    "        action = agent.act(state)\n",
    "        img.set_data(env.render(mode='rgb_array')) \n",
    "        plt.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break \n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHZxhRSHf6yU"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(agent.model, to_file='keras_plot_model_2.png', show_shapes=True)\n",
    "display.Image('keras_plot_model_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPrMm9odgFs7"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os import path\n",
    "\n",
    "save_dir = \"./saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T23:23:14.325962Z",
     "iopub.status.busy": "2023-01-06T23:23:14.325684Z",
     "iopub.status.idle": "2023-01-06T23:23:15.690156Z",
     "shell.execute_reply": "2023-01-06T23:23:15.688756Z",
     "shell.execute_reply.started": "2023-01-06T23:23:14.325938Z"
    },
    "id": "V1d6Ah1GgJ-G"
   },
   "outputs": [],
   "source": [
    "agent.model.save(path.join(save_dir, \"model.tf\"))\n",
    "agent.target_model.save(path.join(save_dir, \"target_model.tf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T23:23:15.702539Z",
     "iopub.status.busy": "2023-01-06T23:23:15.702232Z",
     "iopub.status.idle": "2023-01-06T23:23:15.707097Z",
     "shell.execute_reply": "2023-01-06T23:23:15.706087Z",
     "shell.execute_reply.started": "2023-01-06T23:23:15.702514Z"
    },
    "id": "DjzHcEOHgaun"
   },
   "outputs": [],
   "source": [
    "agent.model = None\n",
    "agent.target_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-06T23:23:15.708619Z",
     "iopub.status.busy": "2023-01-06T23:23:15.708120Z"
    },
    "id": "qU6_sPNKgb7b"
   },
   "outputs": [],
   "source": [
    "with open(path.join(save_dir, \"agent.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(agent, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YV-IOIKZghSn"
   },
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxBJ3gv1ggqA"
   },
   "outputs": [],
   "source": [
    "with open(path.join(save_dir, \"agent.pkl\"), \"rb\") as f:\n",
    "    agent = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "agent.model = tf.keras.models.load_model(path.join(save_dir, \"model.tf\"))\n",
    "agent.target_model = tf.keras.models.load_model(path.join(save_dir, \"target_model.tf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMBpIA_oZE_A"
   },
   "source": [
    "## To-Dos\n",
    "\n",
    "- Create on place for hyperparameters for inside the model and pass it on\n",
    "  - e. g. optimizer, different metrics, checkpointing for the internal model, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5UV7EPfZE_B"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "119d84cb8c3b84b6d48a93e2933b395fcb363c6d1cda3c0de52c91f1ece8e0fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
